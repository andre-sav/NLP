{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "import string\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "yelp = pd.read_json('./data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    tokens = simple_preprocess(doc)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "sparse = tfidf.fit_transform(yelp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf = pd.DataFrame(sparse.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_review = \"Terrible, horrible, disgusting. I will never forgive. I will never forget. Bad.  May the plague descend upon the orchestrators of my misfortune.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_review = tokenize(fake_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=2, p=2, radius=1.0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "nn.fit(dtm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = tfidf.transform(tokenized_review)\n",
    "\n",
    "results = nn.kneighbors(query.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.78770877, 0.8435033 ],\n",
       "        [0.94335743, 1.06494876],\n",
       "        [1.08638262, 1.13996368],\n",
       "        [1.        , 1.        ],\n",
       "        [1.        , 1.        ],\n",
       "        [1.05319219, 1.2822979 ],\n",
       "        [1.        , 1.        ],\n",
       "        [1.        , 1.        ],\n",
       "        [1.12865996, 1.12893219],\n",
       "        [0.76723817, 0.93695451],\n",
       "        [1.        , 1.        ],\n",
       "        [1.        , 1.        ],\n",
       "        [1.26650621, 1.30607639],\n",
       "        [1.28105719, 1.34888228],\n",
       "        [1.        , 1.        ],\n",
       "        [1.        , 1.        ],\n",
       "        [1.        , 1.        ],\n",
       "        [1.        , 1.        ],\n",
       "        [1.        , 1.        ],\n",
       "        [1.22056787, 1.41421356]]), array([[2627, 5298],\n",
       "        [7235, 1922],\n",
       "        [9900, 1759],\n",
       "        [4837, 7181],\n",
       "        [4837, 7181],\n",
       "        [3541, 5725],\n",
       "        [4837, 7181],\n",
       "        [4837, 7181],\n",
       "        [1298, 2867],\n",
       "        [4599, 2518],\n",
       "        [4837, 7181],\n",
       "        [4837, 7181],\n",
       "        [2285, 9500],\n",
       "        [2888, 1316],\n",
       "        [4837, 7181],\n",
       "        [4837, 7181],\n",
       "        [4837, 7181],\n",
       "        [4837, 7181],\n",
       "        [4837, 7181],\n",
       "        [2545, 7073]]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2627    Terrible terrible terrible went to get a \"hot ...\n",
      "5298    Terrible.. absolutely terrible. Dr. Hinds is e...\n",
      "Name: text, dtype: object\n",
      "7235    The service here is horrible. The food wasn't ...\n",
      "1922    Horrible customer service and management unwil...\n",
      "Name: text, dtype: object\n",
      "9900    How they make a person wait  2 hours for a 2 m...\n",
      "1759    For some reason everyone gets sick after a mea...\n",
      "Name: text, dtype: object\n",
      "4837    Beware, I went here when this location first o...\n",
      "7181    I only bother to review businesses when I thin...\n",
      "Name: text, dtype: object\n",
      "4837    Beware, I went here when this location first o...\n",
      "7181    I only bother to review businesses when I thin...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in results[1][:5]:\n",
    "    print(yelp.text[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "the results are primarily negative reviews, as expected\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "parser = English()\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    tokens = parser(sentence)\n",
    "    tokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuations]\n",
    "    return tokens\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.strip().lower()\n",
    "\n",
    "bow_vector = CountVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1,1))\n",
    "tfidf_vector = CountVectorizer(tokenizer=spacy_tokenizer)\n",
    "\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self,X,**transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self,X,y=None,**fit_params):\n",
    "        return self\n",
    "    def get_params(self,deep=True):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifier = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=1000)\n",
    "\n",
    "pipeline = Pipeline([('cleaner', predictors()),\n",
    "                ('vectorizer', bow_vector),\n",
    "                ('clf', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "pipeline = Pipeline([('vect', vect), ('clf', sgdc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(yelp['text'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([fake_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (100, 500,1000),\n",
    "    'clf__max_iter':(20, 10, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, cv=6, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   19.7s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (100, 500, 1000), 'clf__max_iter': (20, 10, 100)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(yelp.text, yelp.stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_iter': 20,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': 1000,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "    - Keep the `iterations` parameter at or below 5 to reduce run time\n",
    "    - The `workers` parameter should match the number of physical cores on your machine.\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the vocubalary of the yelp data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_reviews = yelp.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_list = [simple_preprocess(doc) for doc in list_of_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokenized_list:\n",
    "    for j in i:\n",
    "        if j in stop_words:\n",
    "            i.remove(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(tokenized_list, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[tokenized_list], threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemma(texts):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = make_bigrams(tokenized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatized = lemma(bigrams)\n",
    "\n",
    "lemmatized = lemma(tokenized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.filter_extremes(no_below=20, no_above=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   iterations=25,\n",
    "                   workers=6,\n",
    "                   num_topics = 4 # You can change this parameter\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2993673092496755"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda, texts=lemmatized,\n",
    "                                    dictionary=id2word, coherence='c_v')\n",
    "\n",
    "coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el867891166011112008339650492\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el867891166011112008339650492_data = {\"mdsDat\": {\"x\": [-0.008663574876806898, 0.009271625272266474, 0.001001933096409282, -0.0016099834918688622], \"y\": [-0.0033647489148660474, -0.0011990516958148365, -0.004091230387871296, 0.00865503099855218], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [28.51433753967285, 28.12785530090332, 22.150257110595703, 21.20754623413086]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [32158.0, 26046.0, 18316.0, 6289.0, 5316.0, 4243.0, 6316.0, 3005.0, 3186.0, 3493.0, 3648.0, 6225.0, 1642.0, 5704.0, 905.0, 1094.0, 4334.0, 1344.0, 2647.0, 1288.0, 2708.0, 3912.0, 1565.0, 868.0, 3996.0, 1407.0, 591.0, 1351.0, 1048.0, 1115.0, 90.3853759765625, 18.899089813232422, 28.161773681640625, 40.963653564453125, 12.590143203735352, 28.385051727294922, 29.526350021362305, 60.58935546875, 2473.887939453125, 14.4219970703125, 17.312755584716797, 73.1256103515625, 30.82859992980957, 21.05135726928711, 20.639251708984375, 386.4633483886719, 13.708897590637207, 18.28348159790039, 69.82573699951172, 197.97772216796875, 12.130781173706055, 45.94832992553711, 1843.5277099609375, 34.91864013671875, 82.80297088623047, 39.13935089111328, 2718.791015625, 31.027673721313477, 279.7912902832031, 36.499725341796875, 403.1241149902344, 165.21755981445312, 105.64950561523438, 1107.1822509765625, 208.04852294921875, 227.16925048828125, 185.28173828125, 9544.6689453125, 234.9093780517578, 1124.5819091796875, 165.05148315429688, 1857.9285888671875, 470.13262939453125, 357.2643127441406, 1256.3392333984375, 524.6265258789062, 1409.579345703125, 529.6954956054688, 4959.0458984375, 432.0152282714844, 429.72906494140625, 765.1251220703125, 1020.8043823242188, 509.4590148925781, 832.7011108398438, 6859.48388671875, 1189.199951171875, 1114.9716796875, 1032.1318359375, 435.7691955566406, 862.16455078125, 496.4598693847656, 1361.6212158203125, 658.8760375976562, 1413.571533203125, 1349.4368896484375, 905.1555786132812, 747.580810546875, 964.7435913085938, 670.6597900390625, 808.6766357421875, 846.7306518554688, 598.5952758789062, 629.0352783203125, 646.1490478515625, 633.4114379882812, 68.84928131103516, 59.95922088623047, 34.63024139404297, 98.22299194335938, 35.79323959350586, 22.750484466552734, 27.418453216552734, 28.748754501342773, 42.18648910522461, 205.88002014160156, 27.86759376525879, 20.509981155395508, 115.04367065429688, 22.964174270629883, 152.9601287841797, 18.628210067749023, 19.285146713256836, 76.8544921875, 32.30499267578125, 54.675994873046875, 30.72285270690918, 23.55046272277832, 22.99787139892578, 36.60524368286133, 10.761811256408691, 171.4031219482422, 27.975154876708984, 65.75568389892578, 14.232646942138672, 9.661674499511719, 165.06629943847656, 97.2167739868164, 835.1727294921875, 753.426025390625, 173.7990264892578, 919.1837158203125, 176.42520141601562, 11305.0947265625, 2298.527587890625, 225.45303344726562, 269.8526306152344, 597.9961547851562, 636.9431762695312, 964.6741333007812, 547.9099731445312, 1429.1298828125, 201.9571533203125, 1417.5546875, 494.506591796875, 565.5926513671875, 5301.7998046875, 923.9129638671875, 1951.6007080078125, 1279.1806640625, 633.7611083984375, 1735.2669677734375, 890.4774780273438, 1029.612548828125, 570.23876953125, 5716.07421875, 635.6702880859375, 557.9767456054688, 816.1192626953125, 1074.8662109375, 607.8563232421875, 589.9636840820312, 711.50390625, 1189.9560546875, 1216.1591796875, 963.1213989257812, 1266.8726806640625, 993.3724975585938, 761.0938110351562, 705.7374877929688, 721.9588623046875, 801.9591064453125, 783.9242553710938, 760.3029174804688, 706.6039428710938, 28.19721794128418, 26.898571014404297, 27.76375961303711, 27.0682373046875, 15.253472328186035, 14.673818588256836, 29.203277587890625, 11.592150688171387, 13.904705047607422, 16.148408889770508, 61.32457733154297, 16.583221435546875, 48.9612922668457, 18.15935516357422, 22.45979881286621, 27.014787673950195, 12.149031639099121, 20.362550735473633, 409.7369079589844, 12.305593490600586, 9.02690315246582, 35.61856460571289, 12.035480499267578, 68.79547882080078, 11.821447372436523, 62.77796173095703, 7.94904088973999, 33.86270523071289, 322.25885009765625, 10.45205020904541, 272.36175537109375, 234.8574981689453, 171.72747802734375, 999.0520629882812, 107.0943832397461, 254.24827575683594, 117.6889419555664, 96.41670989990234, 4854.890625, 136.415771484375, 216.53097534179688, 155.6232147216797, 1521.446533203125, 95.06071472167969, 999.5719604492188, 5956.56640625, 6841.7900390625, 286.5863952636719, 437.0079650878906, 398.4265441894531, 822.6246948242188, 866.7970581054688, 681.6343383789062, 319.7784423828125, 1415.348876953125, 484.2139587402344, 1355.9520263671875, 387.6435546875, 1361.0899658203125, 625.0845947265625, 516.7136840820312, 900.0340576171875, 1123.097412109375, 550.078369140625, 849.4827880859375, 910.590087890625, 378.20001220703125, 473.7464599609375, 402.7455139160156, 576.9443969726562, 790.6661987304688, 938.865478515625, 818.8336181640625, 585.08984375, 591.2298583984375, 676.7645874023438, 595.0538330078125, 471.21368408203125, 12.530767440795898, 15.21237564086914, 12.688319206237793, 12.115979194641113, 20.803871154785156, 41.87649154663086, 229.18612670898438, 75.55663299560547, 32.712890625, 32.156063079833984, 30.082202911376953, 31.213502883911133, 14.1099853515625, 9.401611328125, 15.31019401550293, 58.61970520019531, 8.257197380065918, 11.013856887817383, 20.15483283996582, 17.65568733215332, 72.13712310791016, 20.064411163330078, 32.33474349975586, 12.240866661071777, 10.65132999420166, 107.05453491210938, 15.373693466186523, 29.5640811920166, 8.692082405090332, 19.64537239074707, 191.873779296875, 87.54080200195312, 564.1992797851562, 287.9830627441406, 142.56565856933594, 288.8277282714844, 51.95492935180664, 417.7936706542969, 44.64862060546875, 952.5842895507812, 323.1766052246094, 407.2086181640625, 62.5811882019043, 220.59744262695312, 995.5963134765625, 738.8463745117188, 937.9628295898438, 7151.759765625, 1112.9385986328125, 1536.3701171875, 346.745849609375, 377.2711181640625, 493.7957763671875, 405.1487121582031, 404.7982482910156, 591.139892578125, 4829.43310546875, 911.5892944335938, 925.9759521484375, 381.4101257324219, 452.677978515625, 3201.159912109375, 886.36962890625, 651.4564208984375, 1221.3785400390625, 1086.1522216796875, 942.03125, 597.57177734375, 782.5467529296875, 478.6729431152344, 554.6569213867188, 943.09814453125, 704.3345336914062, 535.2405395507812, 516.6411743164062, 579.4860229492188, 687.3619995117188, 529.1553955078125, 483.3203125], \"Term\": [\"-PRON-\", \"the\", \"be\", \"good\", \"place\", \"great\", \"have\", \"back\", \"make\", \"order\", \"one\", \"get\", \"find\", \"go\", \"dish\", \"use\", \"time\", \"menu\", \"well\", \"thing\", \"really\", \"like\", \"ask\", \"cheese\", \"come\", \"recommend\", \"roll\", \"there\", \"with\", \"other\", \"pepper\", \"chorizo\", \"deli\", \"apple\", \"maple\", \"benedict\", \"amaze\", \"mall\", \"place\", \"pepperoni\", \"cappuccino\", \"mushroom\", \"carne\", \"welcoming\", \"mayo\", \"pizza\", \"study\", \"cheesy\", \"ton\", \"ve\", \"fav\", \"margarita\", \"great\", \"north\", \"brunch\", \"combination\", \"good\", \"damn\", \"coffee\", \"yesterday\", \"sauce\", \"pork\", \"park\", \"really\", \"taco\", \"perfect\", \"egg\", \"the\", \"family\", \"this\", \"today\", \"food\", \"on\", \"every\", \"one\", \"people\", \"time\", \"always\", \"be\", \"fry\", \"bad\", \"love\", \"make\", \"definitely\", \"well\", \"-PRON-\", \"to\", \"service\", \"not\", \"delicious\", \"back\", \"drink\", \"go\", \"very\", \"have\", \"get\", \"order\", \"do\", \"come\", \"that\", \"would\", \"like\", \"look\", \"also\", \"take\", \"try\", \"et\", \"le\", \"practice\", \"de\", \"un\", \"en\", \"facial\", \"est\", \"groupon\", \"hair\", \"dental\", \"cart\", \"saturday\", \"record\", \"office\", \"receptionist\", \"convenience\", \"bed\", \"vet\", \"insurance\", \"damage\", \"manner\", \"procedure\", \"refuse\", \"insist\", \"dog\", \"reach\", \"doctor\", \"shuttle\", \"booze\", \"appointment\", \"la\", \"for\", \"in\", \"choice\", \"that\", \"company\", \"-PRON-\", \"get\", \"owner\", \"didn\", \"tell\", \"so\", \"try\", \"chicken\", \"come\", \"pick\", \"to\", \"need\", \"work\", \"be\", \"do\", \"have\", \"like\", \"of\", \"go\", \"and\", \"would\", \"staff\", \"the\", \"want\", \"eat\", \"say\", \"not\", \"nice\", \"restaurant\", \"also\", \"food\", \"place\", \"service\", \"good\", \"time\", \"this\", \"take\", \"well\", \"one\", \"order\", \"make\", \"great\", \"les\", \"est\", \"barber\", \"auto\", \"personality\", \"au\", \"manicure\", \"cab\", \"que\", \"tasteless\", \"phoenix\", \"dealer\", \"pedicure\", \"mussel\", \"buffalo\", \"un\", \"rise\", \"hospital\", \"use\", \"exceed\", \"sear\", \"burn\", \"operate\", \"de\", \"golden\", \"repair\", \"smart\", \"sister\", \"dish\", \"hr\", \"salad\", \"guy\", \"job\", \"back\", \"buffet\", \"big\", \"green\", \"noodle\", \"be\", \"how\", \"car\", \"manager\", \"go\", \"notice\", \"not\", \"the\", \"-PRON-\", \"location\", \"ask\", \"never\", \"would\", \"order\", \"do\", \"other\", \"have\", \"all\", \"get\", \"recommend\", \"good\", \"take\", \"even\", \"like\", \"food\", \"very\", \"service\", \"great\", \"think\", \"want\", \"work\", \"say\", \"to\", \"place\", \"time\", \"and\", \"this\", \"come\", \"one\", \"try\", \"golf\", \"martini\", \"pastor\", \"assortment\", \"omelette\", \"mango\", \"roll\", \"pull\", \"smoothie\", \"dumpling\", \"bagel\", \"tofu\", \"diamond\", \"appetite\", \"plumbing\", \"market\", \"um\", \"press\", \"eggplant\", \"yellow\", \"lose\", \"scratch\", \"brisket\", \"preference\", \"bucket\", \"glass\", \"tight\", \"sub\", \"gentle\", \"pub\", \"hotel\", \"cost\", \"find\", \"long\", \"must\", \"cheese\", \"sample\", \"thing\", \"vegetarian\", \"make\", \"with\", \"menu\", \"soft\", \"super\", \"one\", \"well\", \"order\", \"-PRON-\", \"time\", \"have\", \"new\", \"there\", \"price\", \"experience\", \"could\", \"also\", \"the\", \"service\", \"come\", \"recommend\", \"wait\", \"be\", \"like\", \"and\", \"get\", \"go\", \"food\", \"really\", \"great\", \"look\", \"say\", \"good\", \"to\", \"try\", \"take\", \"would\", \"place\", \"not\", \"back\"], \"Total\": [32158.0, 26046.0, 18316.0, 6289.0, 5316.0, 4243.0, 6316.0, 3005.0, 3186.0, 3493.0, 3648.0, 6225.0, 1642.0, 5704.0, 905.0, 1094.0, 4334.0, 1344.0, 2647.0, 1288.0, 2708.0, 3912.0, 1565.0, 868.0, 3996.0, 1407.0, 591.0, 1351.0, 1048.0, 1115.0, 173.2204132080078, 36.59754943847656, 57.016632080078125, 83.31709289550781, 25.67723846435547, 58.988441467285156, 61.416500091552734, 128.68048095703125, 5316.2744140625, 31.111791610717773, 37.486732482910156, 158.42140197753906, 66.84846496582031, 46.17593765258789, 45.43297576904297, 864.7684936523438, 30.707050323486328, 41.03465270996094, 157.56089782714844, 454.2721252441406, 27.882156372070312, 105.65013885498047, 4243.2685546875, 80.5234603881836, 191.14305114746094, 90.5150146484375, 6289.8515625, 71.82422637939453, 648.8378295898438, 84.83634185791016, 946.0905151367188, 387.6282043457031, 246.93002319335938, 2708.294921875, 495.125732421875, 543.2894287109375, 444.659423828125, 26046.7421875, 569.6993408203125, 2926.794189453125, 399.07501220703125, 5113.013671875, 1217.791748046875, 925.7691650390625, 3648.9482421875, 1440.45703125, 4334.72412109375, 1472.062255859375, 18316.896484375, 1188.20849609375, 1181.7830810546875, 2275.757568359375, 3186.75830078125, 1451.758056640625, 2647.54931640625, 32158.126953125, 4101.75537109375, 3839.1650390625, 3635.7255859375, 1243.292724609375, 3005.94482421875, 1486.464599609375, 5704.4873046875, 2188.962890625, 6316.8916015625, 6225.294921875, 3493.83984375, 2663.11376953125, 3996.6142578125, 2301.8427734375, 3240.39990234375, 3912.31494140625, 1995.9730224609375, 2304.1611328125, 2493.6123046875, 2604.539794921875, 97.87419891357422, 98.53762817382812, 63.91279220581055, 189.52587890625, 70.7673110961914, 44.980770111083984, 54.47118377685547, 57.296348571777344, 84.22148132324219, 415.71612548828125, 58.431861877441406, 43.078556060791016, 248.38690185546875, 49.605438232421875, 332.6888122558594, 40.578392028808594, 42.036563873291016, 167.8960418701172, 70.59200286865234, 121.5300064086914, 68.58812713623047, 52.72093963623047, 51.745296478271484, 82.731201171875, 24.328964233398438, 387.9407958984375, 63.390167236328125, 149.7653350830078, 32.42858123779297, 22.041860580444336, 377.7792053222656, 225.5460662841797, 1993.533203125, 1867.3785400390625, 412.5879211425781, 2301.8427734375, 420.8707275390625, 32158.126953125, 6225.294921875, 545.8433837890625, 662.4882202148438, 1534.61328125, 1657.1622314453125, 2604.539794921875, 1423.3646240234375, 3996.6142578125, 491.6659240722656, 4101.75537109375, 1304.396240234375, 1517.060791015625, 18316.896484375, 2663.11376953125, 6316.8916015625, 3912.31494140625, 1799.048828125, 5704.4873046875, 2726.291015625, 3240.39990234375, 1630.45654296875, 26046.7421875, 1878.3560791015625, 1605.8370361328125, 2571.212158203125, 3635.7255859375, 1806.4967041015625, 1768.691162109375, 2304.1611328125, 5113.013671875, 5316.2744140625, 3839.1650390625, 6289.8515625, 4334.72412109375, 2926.794189453125, 2493.6123046875, 2647.54931640625, 3648.9482421875, 3493.83984375, 3186.75830078125, 4243.2685546875, 55.93486785888672, 57.296348571777344, 60.396907806396484, 59.197776794433594, 35.38557815551758, 35.85089874267578, 72.1484603881836, 28.744403839111328, 34.79376220703125, 40.56310272216797, 154.5463409423828, 42.39604568481445, 126.72164916992188, 47.23139572143555, 58.59990310668945, 70.7673110961914, 31.8311767578125, 53.485107421875, 1094.759521484375, 32.933353424072266, 24.31937599182129, 96.61001586914062, 32.94546127319336, 189.52587890625, 32.83677673339844, 175.53623962402344, 22.274805068969727, 94.96277618408203, 905.9176025390625, 29.442853927612305, 772.8026123046875, 677.8587036132812, 495.35430908203125, 3005.94482421875, 307.6286926269531, 755.161865234375, 344.62957763671875, 280.580810546875, 18316.896484375, 407.09613037109375, 676.3524169921875, 473.12127685546875, 5704.4873046875, 280.25823974609375, 3635.7255859375, 26046.7421875, 32158.126953125, 951.6787109375, 1565.13330078125, 1415.76123046875, 3240.39990234375, 3493.83984375, 2663.11376953125, 1115.4276123046875, 6316.8916015625, 1815.26220703125, 6225.294921875, 1407.9830322265625, 6289.8515625, 2493.6123046875, 1993.6175537109375, 3912.31494140625, 5113.013671875, 2188.962890625, 3839.1650390625, 4243.2685546875, 1386.07861328125, 1878.3560791015625, 1517.060791015625, 2571.212158203125, 4101.75537109375, 5316.2744140625, 4334.72412109375, 2726.291015625, 2926.794189453125, 3996.6142578125, 3648.9482421875, 2604.539794921875, 29.249290466308594, 36.663185119628906, 30.798198699951172, 29.859176635742188, 52.29621887207031, 106.61773681640625, 591.0535888671875, 197.87469482421875, 85.85388946533203, 85.97201538085938, 80.77928924560547, 84.26325988769531, 38.27500915527344, 25.555068969726562, 41.86090850830078, 160.451416015625, 22.60605239868164, 30.42870330810547, 56.08991241455078, 49.18273162841797, 201.00823974609375, 56.13395690917969, 90.73773193359375, 34.353981018066406, 29.970779418945312, 301.6475830078125, 43.381141662597656, 83.55602264404297, 24.566635131835938, 55.74650573730469, 546.9012451171875, 249.31387329101562, 1642.69677734375, 845.96875, 412.83282470703125, 868.59619140625, 149.39010620117188, 1288.7799072265625, 128.98355102539062, 3186.75830078125, 1048.533447265625, 1344.3660888671875, 185.10202026367188, 713.7864990234375, 3648.9482421875, 2647.54931640625, 3493.83984375, 32158.126953125, 4334.72412109375, 6316.8916015625, 1213.3671875, 1351.506591796875, 1839.448486328125, 1480.7388916015625, 1490.0352783203125, 2304.1611328125, 26046.7421875, 3839.1650390625, 3996.6142578125, 1407.9830322265625, 1736.952392578125, 18316.896484375, 3912.31494140625, 2726.291015625, 6225.294921875, 5704.4873046875, 5113.013671875, 2708.294921875, 4243.2685546875, 1995.9730224609375, 2571.212158203125, 6289.8515625, 4101.75537109375, 2604.539794921875, 2493.6123046875, 3240.39990234375, 5316.2744140625, 3635.7255859375, 3005.94482421875], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6043000221252441, 0.5939000248908997, 0.5493999719619751, 0.5447999835014343, 0.5421000123023987, 0.5232999920845032, 0.5224000215530396, 0.5015000104904175, 0.48980000615119934, 0.48590001463890076, 0.4821999967098236, 0.48170000314712524, 0.48080000281333923, 0.4693000018596649, 0.4657000005245209, 0.44929999113082886, 0.44830000400543213, 0.4462999999523163, 0.4410000145435333, 0.42419999837875366, 0.42250001430511475, 0.4221000075340271, 0.421099990606308, 0.41920000314712524, 0.41819998621940613, 0.4163999855518341, 0.41600000858306885, 0.4153999984264374, 0.41359999775886536, 0.41130000352859497, 0.4016999900341034, 0.4020000100135803, 0.4058000147342682, 0.3603000044822693, 0.38769999146461487, 0.38280001282691956, 0.37929999828338623, 0.250900000333786, 0.36890000104904175, 0.29829999804496765, 0.3718999922275543, 0.24240000545978546, 0.30300000309944153, 0.3025999963283539, 0.18850000202655792, 0.24469999969005585, 0.131400004029274, 0.23260000348091125, -0.05180000141263008, 0.24300000071525574, 0.24310000240802765, 0.1647000014781952, 0.11630000174045563, 0.20759999752044678, 0.09799999743700027, -0.29030001163482666, 0.016599999740719795, 0.018300000578165054, -0.004399999976158142, 0.20640000700950623, 0.005900000222027302, 0.15809999406337738, -0.1777999997138977, 0.054099999368190765, -0.24230000376701355, -0.2741999924182892, -0.09589999914169312, -0.015599999576807022, -0.16660000383853912, 0.02160000056028366, -0.13330000638961792, -0.27570000290870667, 0.05050000175833702, -0.04349999874830246, -0.09570000320672989, -0.1590999960899353, 0.9165999889373779, 0.7716000080108643, 0.6556000113487244, 0.6111000180244446, 0.5867999792098999, 0.5867999792098999, 0.5820000171661377, 0.5788000226020813, 0.5770999789237976, 0.5656999945640564, 0.527999997138977, 0.5263000130653381, 0.49869999289512634, 0.498199999332428, 0.49140000343322754, 0.48989999294281006, 0.48919999599456787, 0.4869999885559082, 0.48669999837875366, 0.46970000863075256, 0.4652999937534332, 0.4625000059604645, 0.45750001072883606, 0.453000009059906, 0.4526999890804291, 0.45159998536109924, 0.4503999948501587, 0.44530001282691956, 0.4449000060558319, 0.44359999895095825, 0.44040000438690186, 0.426800012588501, 0.3984000086784363, 0.36070001125335693, 0.40389999747276306, 0.35040000081062317, 0.39899998903274536, 0.22300000488758087, 0.2721000015735626, 0.38420000672340393, 0.3702999949455261, 0.32600000500679016, 0.31220000982284546, 0.2752000093460083, 0.31369999051094055, 0.23999999463558197, 0.37869998812675476, 0.20589999854564667, 0.2985000014305115, 0.2818000018596649, 0.028599999845027924, 0.20980000495910645, 0.09380000084638596, 0.15049999952316284, 0.22509999573230743, 0.07829999923706055, 0.14949999749660492, 0.12189999967813492, 0.21780000627040863, -0.24819999933242798, 0.18490000069141388, 0.21130000054836273, 0.12080000340938568, 0.049800001084804535, 0.17919999361038208, 0.1704999953508377, 0.093299999833107, -0.18950000405311584, -0.20669999718666077, -0.1143999993801117, -0.33399999141693115, -0.20489999651908875, -0.07850000262260437, 0.006200000178068876, -0.03099999949336052, -0.2467000037431717, -0.22599999606609344, -0.16459999978542328, -0.5242000222206116, 0.8223999738693237, 0.7512000203132629, 0.7300999760627747, 0.7247999906539917, 0.6657999753952026, 0.6140000224113464, 0.6029000282287598, 0.5992000102996826, 0.5900999903678894, 0.5863000154495239, 0.5830000042915344, 0.5687000155448914, 0.5564000010490417, 0.5514000058174133, 0.54830002784729, 0.5443000197410583, 0.5440999865531921, 0.5415999889373779, 0.5245000123977661, 0.5228999853134155, 0.5163000226020813, 0.5095000267028809, 0.5002999901771545, 0.49390000104904175, 0.48570001125335693, 0.47909998893737793, 0.47690001130104065, 0.47620001435279846, 0.47369998693466187, 0.4717000126838684, 0.4643999934196472, 0.4474000036716461, 0.4480000138282776, 0.4058000147342682, 0.45210000872612, 0.4187000095844269, 0.43290001153945923, 0.4390999972820282, 0.17949999868869781, 0.414000004529953, 0.3682999908924103, 0.3953999876976013, 0.18569999933242798, 0.4260999858379364, 0.21610000729560852, 0.03189999982714653, -0.040300000458955765, 0.30709999799728394, 0.23149999976158142, 0.2393999993801117, 0.1363999992609024, 0.11339999735355377, 0.1446000039577484, 0.257999986410141, 0.011500000022351742, 0.1859000027179718, -0.01679999940097332, 0.2175000011920929, -0.02329999953508377, 0.12370000034570694, 0.15710000693798065, 0.03790000081062317, -0.00839999970048666, 0.12620000541210175, -0.0010999999940395355, -0.031700000166893005, 0.2084999978542328, 0.1298000067472458, 0.181099995970726, 0.012900000438094139, -0.13899999856948853, -0.226500004529953, -0.15919999778270721, -0.031599998474121094, -0.09210000187158585, -0.2685999870300293, -0.3061999976634979, -0.20239999890327454, 0.7031000256538391, 0.6711000204086304, 0.6639999747276306, 0.6488000154495239, 0.6290000081062317, 0.6162999868392944, 0.6033999919891357, 0.588100016117096, 0.5859000086784363, 0.5673999786376953, 0.5630000233650208, 0.557699978351593, 0.5529000163078308, 0.5508999824523926, 0.5450000166893005, 0.5439000129699707, 0.5436999797821045, 0.534600019454956, 0.5273000001907349, 0.5263000130653381, 0.5260000228881836, 0.5220000147819519, 0.5189999938011169, 0.5188999772071838, 0.5163000226020813, 0.5149000287055969, 0.5134000182151794, 0.511900007724762, 0.5117999911308289, 0.5077999830245972, 0.5034000277519226, 0.5041999816894531, 0.4821000099182129, 0.4731999933719635, 0.4875999987125397, 0.4498000144958496, 0.49459999799728394, 0.4242999851703644, 0.49000000953674316, 0.3431999981403351, 0.37389999628067017, 0.3564999997615814, 0.46639999747276306, 0.3765999972820282, 0.25200000405311584, 0.2745000123977661, 0.23579999804496765, 0.04749999940395355, 0.19120000302791595, 0.13699999451637268, 0.29829999804496765, 0.27480000257492065, 0.23569999635219574, 0.2547999918460846, 0.2476000040769577, 0.19040000438690186, -0.13439999520778656, 0.11299999803304672, 0.0885000005364418, 0.24480000138282776, 0.2061000019311905, -0.19349999725818634, 0.06610000133514404, 0.1193000003695488, -0.07779999822378159, -0.10779999941587448, -0.14069999754428864, 0.03959999978542328, -0.1396999955177307, 0.12290000170469284, 0.017000000923871994, -0.3467000126838684, -0.2110999971628189, -0.03150000050663948, -0.02329999953508377, -0.1704999953508377, -0.4948999881744385, -0.3765000104904175, -0.2768999934196472], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.597899913787842, -9.162799835205078, -8.763999938964844, -8.389300346374512, -9.569000244140625, -8.756099700927734, -8.716699600219727, -7.997799873352051, -4.288400173187256, -9.433199882507324, -9.250499725341797, -7.809800148010254, -8.673500061035156, -9.055000305175781, -9.074700355529785, -6.144899845123291, -9.48390007019043, -9.195899963378906, -7.855899810791016, -6.813799858093262, -9.606200218200684, -8.274399757385254, -4.582499980926514, -8.54889965057373, -7.685500144958496, -8.434800148010254, -4.193999767303467, -8.667099952697754, -6.467899799346924, -8.504599571228027, -6.102700233459473, -6.994699954986572, -7.441800117492676, -5.092400074005127, -6.764200210571289, -6.676199913024902, -6.880099773406982, -2.938199996948242, -6.6427001953125, -5.0767998695373535, -6.995699882507324, -4.574699878692627, -5.94890022277832, -6.223499774932861, -4.966000080108643, -5.839300155639648, -4.850900173187256, -5.829599857330322, -3.5929999351501465, -6.0335001945495605, -6.03879976272583, -5.461900234222412, -5.173600196838379, -5.868599891662598, -5.377299785614014, -3.2685999870300293, -5.020899772644043, -5.085400104522705, -5.162600040435791, -6.024799823760986, -5.34250020980835, -5.894400119781494, -4.885499954223633, -5.611400127410889, -4.848100185394287, -4.894499778747559, -5.293799877166748, -5.485099792480469, -5.230100154876709, -5.593699932098389, -5.406499862670898, -5.360599994659424, -5.707399845123291, -5.657800197601318, -5.630899906158447, -5.6508002281188965, -7.856400012969971, -7.99459981918335, -8.543600082397461, -7.501100063323975, -8.510499954223633, -8.963700294494629, -8.777099609375, -8.729700088500977, -8.346199989318848, -6.761000156402588, -8.7608003616333, -9.067399978637695, -7.3429999351501465, -8.954400062561035, -7.05810022354126, -9.163599967956543, -9.128999710083008, -7.746399879455566, -8.613100051879883, -8.086899757385254, -8.663299560546875, -8.929200172424316, -8.952899932861328, -8.488100051879883, -9.712300300598145, -6.944300174713135, -8.756999969482422, -7.902400016784668, -9.43280029296875, -9.820099830627441, -6.98199987411499, -7.51140022277832, -5.3607001304626465, -5.463699817657471, -6.9303998947143555, -5.264800071716309, -6.91540002822876, -2.7553000450134277, -4.348299980163574, -6.670199871063232, -6.4903998374938965, -5.694699764251709, -5.6315999031066895, -5.2164998054504395, -5.782199859619141, -4.823500156402588, -6.780200004577637, -4.831600189208984, -5.884699821472168, -5.750400066375732, -3.512500047683716, -5.259699821472168, -4.511899948120117, -4.934299945831299, -5.636600017547607, -4.62939977645874, -5.296500205993652, -5.151400089263916, -5.742199897766113, -3.437299966812134, -5.633600234985352, -5.763999938964844, -5.383699893951416, -5.10830020904541, -5.678400039672852, -5.708199977874756, -5.520899772644043, -5.0065999031066895, -4.984799861907959, -5.218100070953369, -4.943999767303467, -5.18720006942749, -5.453499794006348, -5.529099941253662, -5.50629997253418, -5.401199817657471, -5.423999786376953, -5.454599857330322, -5.5278000831604, -8.510199546813965, -8.557299613952637, -8.525699615478516, -8.550999641418457, -9.124600410461426, -9.163299560546875, -8.475099563598633, -9.399100303649902, -9.21720027923584, -9.06760025024414, -7.7332000732421875, -9.041000366210938, -7.958399772644043, -8.950200080871582, -8.737700462341309, -8.553000450134277, -9.352100372314453, -8.835700035095215, -5.833899974822998, -9.339300155639648, -9.649200439453125, -8.27649974822998, -9.361499786376953, -7.618199825286865, -9.379500389099121, -7.709799766540527, -9.776300430297852, -8.327099800109863, -6.073999881744385, -9.502599716186523, -6.242300033569336, -6.390399932861328, -6.703499794006348, -4.942599773406982, -7.1757001876831055, -6.311100006103516, -7.081299781799316, -7.280700206756592, -3.361599922180176, -6.933700084686279, -6.471700191497803, -6.8018999099731445, -4.521999835968018, -7.294899940490723, -4.9421000480651855, -3.157099962234497, -3.0185999870300293, -6.191299915313721, -5.769400119781494, -5.8618998527526855, -5.136899948120117, -5.08459997177124, -5.324900150299072, -6.0817999839782715, -4.594299793243408, -5.666900157928467, -4.6371002197265625, -5.8892998695373535, -4.633299827575684, -5.411499977111816, -5.601900100708008, -5.046999931335449, -4.825500011444092, -5.539299964904785, -5.104800224304199, -5.035299777984619, -5.914000034332275, -5.688700199127197, -5.851099967956543, -5.491600036621094, -5.176499843597412, -5.004700183868408, -5.141499996185303, -5.47760009765625, -5.467199802398682, -5.332099914550781, -5.460700035095215, -5.6940999031066895, -9.277700424194336, -9.083800315856934, -9.265199661254883, -9.311400413513184, -8.77079963684082, -8.071200370788574, -6.371399879455566, -7.480999946594238, -8.318099975585938, -8.33530044555664, -8.402000427246094, -8.364999771118164, -9.159000396728516, -9.5649995803833, -9.077400207519531, -7.734799861907959, -9.69480037689209, -9.406700134277344, -8.802399635314941, -8.934800148010254, -7.527299880981445, -8.806900024414062, -8.32979965209961, -9.30109977722168, -9.440199851989746, -7.132599830627441, -9.073200225830078, -8.419300079345703, -9.643500328063965, -8.828100204467773, -6.549099922180176, -7.333799839019775, -5.4704999923706055, -6.14300012588501, -6.846099853515625, -6.140100002288818, -7.855500221252441, -5.770899772644043, -8.007100105285645, -4.946700096130371, -6.027699947357178, -5.796599864959717, -7.669400215148926, -6.409599781036377, -4.902599811553955, -5.200799942016602, -4.962200164794922, -2.930799961090088, -4.791100025177002, -4.468699932098389, -5.957300186157227, -5.872900009155273, -5.603799819946289, -5.801599979400635, -5.802499771118164, -5.423799991607666, -3.3234000205993652, -4.990699768066406, -4.974999904632568, -5.861999988555908, -5.690700054168701, -3.734600067138672, -5.018799781799316, -5.326700210571289, -4.698200225830078, -4.815499782562256, -4.957900047302246, -5.413000106811523, -5.1433000564575195, -5.634900093078613, -5.487500190734863, -4.956699848175049, -5.248600006103516, -5.523200035095215, -5.558499813079834, -5.44379997253418, -5.2729997634887695, -5.534599781036377, -5.625199794769287]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4], \"Freq\": [0.2132897824048996, 0.3515441119670868, 0.21276114881038666, 0.22240100800991058, 0.23192241787910461, 0.3250219225883484, 0.2666281461715698, 0.1762830764055252, 0.2729843854904175, 0.3090061545372009, 0.16144704818725586, 0.2564924657344818, 0.3600391149520874, 0.3321870267391205, 0.1827368438243866, 0.12499471008777618, 0.48846808075904846, 0.19538722932338715, 0.24423404037952423, 0.08141134679317474, 0.21971242129802704, 0.3264508545398712, 0.21457724273204803, 0.23878595232963562, 0.23478707671165466, 0.19565589725971222, 0.19565589725971222, 0.3521806299686432, 0.4920958876609802, 0.16803275048732758, 0.16803275048732758, 0.16803275048732758, 0.14029358327388763, 0.43676304817199707, 0.3176458477973938, 0.1032349020242691, 0.26770883798599243, 0.19231589138507843, 0.2792094349861145, 0.2606806755065918, 0.2009432464838028, 0.2009432464838028, 0.2009432464838028, 0.4018864929676056, 0.11157321184873581, 0.36261293292045593, 0.41839954257011414, 0.1394665241241455, 0.18581779301166534, 0.18581779301166534, 0.45609819889068604, 0.16892525553703308, 0.28676506876945496, 0.2198975831270218, 0.33234143257141113, 0.1606815904378891, 0.3638569712638855, 0.21916034817695618, 0.19292880594730377, 0.22423742711544037, 0.23520880937576294, 0.19807057082653046, 0.18569116294384003, 0.37138232588768005, 0.23179994523525238, 0.21524280309677124, 0.46359989047050476, 0.09934283792972565, 0.27073362469673157, 0.2894595265388489, 0.2650558054447174, 0.17475667595863342, 0.21441839635372162, 0.45861712098121643, 0.10720919817686081, 0.2203744649887085, 0.4746692478656769, 0.16952472925186157, 0.16952472925186157, 0.16952472925186157, 0.2714649736881256, 0.2211446464061737, 0.3363517224788666, 0.16950008273124695, 0.22684110701084137, 0.45368221402168274, 0.18147288262844086, 0.13610465824604034, 0.2534777820110321, 0.1983739286661148, 0.18735314905643463, 0.3526647686958313, 0.4342297613620758, 0.22496239840984344, 0.1935722976922989, 0.14648714661598206, 0.266926646232605, 0.266926646232605, 0.1334633231163025, 0.36702415347099304, 0.27303799986839294, 0.1706487536430359, 0.37542724609375, 0.1706487536430359, 0.2047923356294632, 0.24705107510089874, 0.3478219211101532, 0.20154166221618652, 0.238070547580719, 0.22771966457366943, 0.3726321756839752, 0.1656142920255661, 0.20873628556728363, 0.2435256689786911, 0.41747257113456726, 0.1391575187444687, 0.45349377393722534, 0.16005662083625793, 0.08002831041812897, 0.2934371531009674, 0.23804157972335815, 0.3444949686527252, 0.32083866000175476, 0.09758226573467255, 0.4637354016304016, 0.19446969032287598, 0.11967365443706512, 0.20942889153957367, 0.2089206576347351, 0.4874815344810486, 0.11606702953577042, 0.1857072412967682, 0.3027874231338501, 0.14736421406269073, 0.21759247779846191, 0.3327207863330841, 0.4386536478996277, 0.17058752477169037, 0.21932682394981384, 0.17058752477169037, 0.25994744896888733, 0.3850032389163971, 0.17493760585784912, 0.18055808544158936, 0.2254064977169037, 0.4217282831668854, 0.1866268813610077, 0.1672370880842209, 0.5191604495048523, 0.1366211622953415, 0.1366211622953415, 0.1912696361541748, 0.4315408170223236, 0.20806431770324707, 0.2065231055021286, 0.15412171185016632, 0.4308677315711975, 0.15467047691345215, 0.19886203110218048, 0.20990993082523346, 0.2414543777704239, 0.3575526475906372, 0.1693933755159378, 0.23169611394405365, 0.16156980395317078, 0.4181806743144989, 0.23997867107391357, 0.17820198833942413, 0.16652169823646545, 0.45198747515678406, 0.2378881424665451, 0.1427328884601593, 0.22862747311592102, 0.1764843612909317, 0.2446715086698532, 0.3529687225818634, 0.2181156426668167, 0.27918800711631775, 0.23086701333522797, 0.27180564403533936, 0.17495739459991455, 0.4519732594490051, 0.14579783380031586, 0.2186967432498932, 0.43160924315452576, 0.2088431864976883, 0.13922879099845886, 0.2088431864976883, 0.05803956836462021, 0.517079770565033, 0.36406636238098145, 0.06331589072942734, 0.21228395402431488, 0.2358710616827011, 0.40098080039024353, 0.16510973870754242, 0.3506093919277191, 0.24246464669704437, 0.20733481645584106, 0.19975779950618744, 0.4910847842693329, 0.14030992984771729, 0.1753874272108078, 0.19292616844177246, 0.35068169236183167, 0.20107895135879517, 0.21957822144031525, 0.22842569649219513, 0.23959530889987946, 0.4791906177997589, 0.10268370062112808, 0.1882534623146057, 0.2873937785625458, 0.2351403683423996, 0.10450683534145355, 0.36577391624450684, 0.212833970785141, 0.40755441784858704, 0.14641769230365753, 0.2339664250612259, 0.2075243890285492, 0.15233173966407776, 0.3554407060146332, 0.2847941219806671, 0.28087422251701355, 0.3469622731208801, 0.2560912072658539, 0.11640509217977524, 0.2136676013469696, 0.44068941473960876, 0.19363626837730408, 0.15357358753681183, 0.29643699526786804, 0.4407888948917389, 0.15466277301311493, 0.1056862324476242, 0.33367764949798584, 0.3027317225933075, 0.11907447874546051, 0.24487634003162384, 0.2675289213657379, 0.24426552653312683, 0.11631692200899124, 0.372214138507843, 0.23975035548210144, 0.3474823236465454, 0.19366846978664398, 0.21920032799243927, 0.4160487651824951, 0.16641950607299805, 0.26986947655677795, 0.14842820167541504, 0.21394221484661102, 0.21394221484661102, 0.21394221484661102, 0.35657036304473877, 0.11115860939025879, 0.5113295912742615, 0.33347582817077637, 0.044463444501161575, 0.017453119158744812, 0.5061404705047607, 0.4712342321872711, 0.017453119158744812, 0.03065159171819687, 0.7049866318702698, 0.2554299235343933, 0.010217197239398956, 0.2713660001754761, 0.31249725818634033, 0.25932756066322327, 0.15700101852416992, 0.38562527298927307, 0.2657249867916107, 0.20523475110530853, 0.14258414506912231, 0.21255047619342804, 0.21255047619342804, 0.36437225341796875, 0.18218612670898438, 0.2694600522518158, 0.2802654802799225, 0.17626334726810455, 0.2735120952129364, 0.14686664938926697, 0.4956749379634857, 0.14686664938926697, 0.20194163918495178, 0.4124982953071594, 0.20537148416042328, 0.1790418028831482, 0.2036161720752716, 0.43038278818130493, 0.1793261617422104, 0.1434609293937683, 0.21519139409065247, 0.265417218208313, 0.23193567991256714, 0.15888507664203644, 0.34333786368370056, 0.36338648200035095, 0.23273944854736328, 0.21963563561439514, 0.18423576653003693, 0.262849897146225, 0.41885432600975037, 0.18509849905967712, 0.13292981684207916, 0.3635725677013397, 0.22723284363746643, 0.1750534474849701, 0.23480728268623352, 0.16282245516777039, 0.28493931889533997, 0.20352807641029358, 0.36635053157806396, 0.21669656038284302, 0.3692997694015503, 0.21782100200653076, 0.1961352825164795, 0.18896223604679108, 0.29504629969596863, 0.15912608802318573, 0.35471856594085693, 0.23875941336154938, 0.30414652824401855, 0.26663219928741455, 0.19037644565105438, 0.2740829288959503, 0.18272195756435394, 0.3654439151287079, 0.18272195756435394, 0.23932205140590668, 0.20513318479061127, 0.10256659239530563, 0.44445523619651794, 0.4322836399078369, 0.20143559575080872, 0.2163802981376648, 0.14992403984069824, 0.43457067012786865, 0.16661684215068817, 0.21469298005104065, 0.18452756106853485, 0.2843632996082306, 0.1595916450023651, 0.34239661693573, 0.21472330391407013, 0.11873455345630646, 0.4986851215362549, 0.20184874534606934, 0.17810183763504028, 0.25669065117836, 0.200631782412529, 0.3466799259185791, 0.19620607793331146, 0.21889936923980713, 0.49553045630455017, 0.1683841347694397, 0.11786889284849167, 0.2238442748785019, 0.3090127408504486, 0.22400258481502533, 0.24315756559371948, 0.16827113926410675, 0.2804518938064575, 0.37393587827682495, 0.18696793913841248, 0.25964468717575073, 0.24501681327819824, 0.14627869427204132, 0.3510688543319702, 0.24318580329418182, 0.20633946359157562, 0.33407342433929443, 0.21370874345302582, 0.16982048749923706, 0.20378459990024567, 0.3396409749984741, 0.23774869740009308, 0.20831342041492462, 0.40323907136917114, 0.21955913305282593, 0.1686856746673584, 0.20551635324954987, 0.45213598012924194, 0.16441307961940765, 0.16441307961940765, 0.19748209416866302, 0.4525631368160248, 0.23039577901363373, 0.12342631071805954, 0.2119694948196411, 0.181688129901886, 0.34722620248794556, 0.26041966676712036, 0.2305515706539154, 0.43006736040115356, 0.23498526215553284, 0.1019747331738472, 0.030445221811532974, 0.6089044213294983, 0.32474905252456665, 0.030445221811532974, 0.03575587272644043, 0.41119253635406494, 0.500582218170166, 0.03575587272644043, 0.21649585664272308, 0.3269164264202118, 0.23004283010959625, 0.2264643907546997, 0.2437797486782074, 0.23117046058177948, 0.30157235264778137, 0.22381502389907837, 0.24587196111679077, 0.2541465163230896, 0.15958036482334137, 0.3404380977153778, 0.3001042604446411, 0.24298925697803497, 0.21743780374526978, 0.2399832010269165, 0.2039717435836792, 0.2736206352710724, 0.16417238116264343, 0.3581942617893219, 0.3361518085002899, 0.26145139336586, 0.20081225037574768, 0.20125167071819305, 0.3203882873058319, 0.2384868711233139, 0.14215072989463806, 0.299049973487854, 0.4740423560142517, 0.20982202887535095, 0.13988135755062103, 0.17873728275299072, 0.23249852657318115, 0.26208925247192383, 0.3297251760959625, 0.17543070018291473, 0.19696535170078278, 0.20634464919567108, 0.20634464919567108, 0.39393070340156555, 0.1108824759721756, 0.2910664975643158, 0.4019489884376526, 0.1940443366765976, 0.13277456164360046, 0.4552270770072937, 0.2086457461118698, 0.2086457461118698, 0.5062849521636963, 0.15577998757362366, 0.15577998757362366, 0.19472499191761017, 0.4353993237018585, 0.19876925647258759, 0.20823445916175842, 0.16090844571590424, 0.2181345671415329, 0.2492966502904892, 0.16827523708343506, 0.3677125573158264, 0.21820253133773804, 0.2454778552055359, 0.10910126566886902, 0.4091297686100006, 0.46221932768821716, 0.17608356475830078, 0.17608356475830078, 0.19809399545192719, 0.21273967623710632, 0.21497119963169098, 0.27001574635505676, 0.30274492502212524, 0.4607963263988495, 0.13887012004852295, 0.17043152451515198, 0.22724202275276184, 0.21172358095645905, 0.23289594054222107, 0.38110244274139404, 0.14820650219917297, 0.2640293836593628, 0.21316134929656982, 0.17924931645393372, 0.34638717770576477, 0.2514573335647583, 0.3794859051704407, 0.22539164125919342, 0.1441279798746109, 0.2867715060710907, 0.2323838174343109, 0.28112083673477173, 0.19918613135814667, 0.23818016052246094, 0.2530149221420288, 0.22334541380405426, 0.28598102927207947, 0.2502080500125885, 0.33656302094459534, 0.2059234380722046, 0.2070305496454239, 0.22453424334526062, 0.16038160026073456, 0.3421474099159241, 0.2708666920661926, 0.43465593457221985, 0.2483748197555542, 0.1366061568260193, 0.17386236786842346, 0.2838498055934906, 0.2956768870353699, 0.27504825592041016, 0.1455005258321762, 0.2319289594888687, 0.21765640377998352, 0.3389730751514435, 0.21408826112747192, 0.3112756013870239, 0.35240843892097473, 0.17064572870731354, 0.16564308106899261, 0.2885579466819763, 0.4598892331123352, 0.14728479087352753, 0.10520341992378235, 0.19121840596199036, 0.19121840596199036, 0.21034026145935059, 0.40155866742134094, 0.3859444856643677, 0.27180343866348267, 0.18886645138263702, 0.15273547172546387, 0.3442087769508362, 0.21978935599327087, 0.16306068003177643, 0.27295535802841187, 0.2124723643064499, 0.24282555282115936, 0.36423832178115845, 0.18211916089057922, 0.2590273320674896, 0.22439494729042053, 0.2481510490179062, 0.2684725224971771, 0.20261287689208984, 0.23578400909900665, 0.28688549995422363, 0.27433425188064575, 0.2656439542770386, 0.41220614314079285, 0.16488246619701385, 0.15572232007980347, 0.429271399974823, 0.22678489983081818, 0.18628759682178497, 0.15793947875499725, 0.32469430565834045, 0.1298777312040329, 0.16234715282917023, 0.42210260033607483, 0.1972827911376953, 0.23673933744430542, 0.38667425513267517, 0.1815001666545868, 0.36446765065193176, 0.26866471767425537, 0.14648129045963287, 0.22076326608657837, 0.5195692777633667, 0.16164377331733704, 0.12700581550598145, 0.19050872325897217, 0.4499901533126831, 0.1285686194896698, 0.22499507665634155, 0.16071076691150665, 0.4178251624107361, 0.18774522840976715, 0.16565756499767303, 0.2282392978668213, 0.22608080506324768, 0.16956061124801636, 0.4239014983177185, 0.16956061124801636, 0.1941165328025818, 0.14882268011569977, 0.39470362663269043, 0.2588220536708832, 0.22779695689678192, 0.41084808111190796, 0.18305112421512604, 0.17898331582546234, 0.4463622272014618, 0.16883131861686707, 0.19427165389060974, 0.19080251455307007, 0.465363472700119, 0.22873160243034363, 0.17662745714187622, 0.12922583520412445, 0.14333181083202362, 0.35832953453063965, 0.14333181083202362, 0.35832953453063965, 0.42566561698913574, 0.1780056208372116, 0.1418885439634323, 0.25281956791877747, 0.17210951447486877, 0.5476211905479431, 0.15646320581436157, 0.12517055869102478, 0.23286966979503632, 0.17465224862098694, 0.23286966979503632, 0.3493044972419739, 0.29577335715293884, 0.13145482540130615, 0.19718223810195923, 0.3615007698535919, 0.2935662567615509, 0.2343093603849411, 0.20386545360088348, 0.2685587704181671, 0.1739288568496704, 0.4444848299026489, 0.1739288568496704, 0.1932542771100998, 0.16144509613513947, 0.23319847881793976, 0.25113680958747864, 0.3587668836116791, 0.2324703484773636, 0.24763146042823792, 0.13644999265670776, 0.3840814530849457, 0.11496313661336899, 0.40237095952033997, 0.40237095952033997, 0.08622235059738159, 0.22085444629192352, 0.44170889258384705, 0.14197786152362823, 0.2050791233778, 0.4087442457675934, 0.25218820571899414, 0.11815552413463593, 0.2208031266927719, 0.22179292142391205, 0.4682295024394989, 0.14786194264888763, 0.17250560224056244, 0.2173321694135666, 0.2365085333585739, 0.2755714952945709, 0.2705998420715332, 0.16127264499664307, 0.4636588394641876, 0.18143172562122345, 0.18143172562122345, 0.20548474788665771, 0.4472315013408661, 0.18131007254123688, 0.16922272741794586, 0.2449636608362198, 0.2620541453361511, 0.358900249004364, 0.13102707266807556, 0.30135276913642883, 0.33357998728752136, 0.23294061422348022, 0.1323012262582779, 0.21991018950939178, 0.25132593512535095, 0.37698888778686523, 0.15707869827747345, 0.24194084107875824, 0.16918939352035522, 0.19964349269866943, 0.3874437212944031, 0.2898540794849396, 0.2277425080537796, 0.35196569561958313, 0.13069313764572144, 0.24767369031906128, 0.23428593575954437, 0.16734708845615387, 0.34808194637298584, 0.1610390841960907, 0.46298736333847046, 0.1368832290172577, 0.23753266036510468, 0.42596346139907837, 0.15643323957920074, 0.211396262049675, 0.2061113566160202, 0.2422981709241867, 0.3173600435256958, 0.22440777719020844, 0.21585150063037872, 0.24940340220928192, 0.21377435326576233, 0.17814528942108154, 0.3562905788421631, 0.205597385764122, 0.205597385764122, 0.3700752854347229, 0.205597385764122, 0.2904277443885803, 0.2508357763290405, 0.22114183008670807, 0.23755165934562683, 0.24669596552848816, 0.4317179322242737, 0.1541849821805954, 0.18502196669578552, 0.22113928198814392, 0.2632610499858856, 0.35803502798080444, 0.15795662999153137, 0.2693626284599304, 0.1795750856399536, 0.3591501712799072, 0.1795750856399536, 0.23295392096042633, 0.24460162222385406, 0.13977235555648804, 0.3843739628791809, 0.29689309000968933, 0.38439205288887024, 0.18223924934864044, 0.13577426970005035, 0.18368248641490936, 0.22690190374851227, 0.24851159751415253, 0.340352863073349, 0.24901001155376434, 0.3495953381061554, 0.19197076559066772, 0.20975719392299652, 0.45592135190963745, 0.26052647829055786, 0.13026323914527893, 0.13026323914527893, 0.16755224764347076, 0.25132837891578674, 0.22739234566688538, 0.3590405583381653, 0.3404379189014435, 0.17372141778469086, 0.1765233725309372, 0.3096163868904114, 0.4200953245162964, 0.13733884692192078, 0.18177200853824615, 0.2605398893356323, 0.25906193256378174, 0.2831234037876129, 0.2506403923034668, 0.20732975006103516, 0.22187651693820953, 0.19722357392311096, 0.3944471478462219, 0.19722357392311096, 0.23132863640785217, 0.38967472314834595, 0.18050150573253632, 0.19874714314937592, 0.2915055751800537, 0.39924535155296326, 0.1720360815525055, 0.13728131353855133, 0.3664565682411194, 0.2194516360759735, 0.22870422899723053, 0.1853974610567093, 0.19903713464736938, 0.26562947034835815, 0.25601059198379517, 0.27894794940948486, 0.1800152212381363, 0.3251136839389801, 0.17070408165454865, 0.32433778047561646, 0.2893053889274597, 0.2669401168823242, 0.2727118134498596, 0.17098596692085266, 0.3843795955181122, 0.2600114643573761, 0.20192742347717285, 0.15375185012817383, 0.23051491379737854, 0.16136044263839722, 0.2535664141178131, 0.3457723557949066, 0.32528021931648254, 0.22908031940460205, 0.18893936276435852, 0.256763756275177, 0.28987589478492737, 0.34570565819740295, 0.19284427165985107, 0.17163383960723877, 0.41345611214637756, 0.18292300403118134, 0.21800412237644196, 0.18542879819869995, 0.15427838265895844, 0.2136162370443344, 0.26108649373054504, 0.36789461970329285, 0.4442726671695709, 0.19674932956695557, 0.1396285593509674, 0.2157895863056183, 0.2430371791124344, 0.3705069124698639, 0.18083809316158295, 0.20541056990623474, 0.17694376409053802, 0.26541563868522644, 0.22117970883846283, 0.35388752818107605, 0.07065408676862717, 0.5087094306945801, 0.38153210282325745, 0.04239245504140854, 0.213745579123497, 0.18451540172100067, 0.3745114803314209, 0.22744721174240112, 0.43586209416389465, 0.23994427919387817, 0.16509927809238434, 0.15849530696868896, 0.2403407245874405, 0.2093290239572525, 0.2093290239572525, 0.34888169169425964, 0.30105581879615784, 0.24532166123390198, 0.25126054883003235, 0.20237894356250763, 0.2408204823732376, 0.45330914855003357, 0.19832274317741394, 0.09916137158870697, 0.318949431180954, 0.20725956559181213, 0.21301677823066711, 0.26080161333084106, 0.18846267461776733, 0.3385939598083496, 0.2523483335971832, 0.22093787789344788, 0.45478230714797974, 0.3031882047653198, 0.1515941023826599, 0.08662520349025726, 0.3146305978298187, 0.2727050185203552, 0.13370855152606964, 0.27912604808807373, 0.20027972757816315, 0.2412893921136856, 0.24987280368804932, 0.3080492913722992, 0.21488921344280243, 0.37308984994888306, 0.26564526557922363, 0.14699476957321167, 0.24966053664684296, 0.31786200404167175, 0.25398099422454834, 0.1786816567182541, 0.2033233940601349, 0.24398808181285858, 0.18299105763435364, 0.3659821152687073, 0.4243464469909668, 0.2357480227947235, 0.1296614110469818, 0.20038582384586334], \"Term\": [\"-PRON-\", \"-PRON-\", \"-PRON-\", \"-PRON-\", \"all\", \"all\", \"all\", \"all\", \"also\", \"also\", \"also\", \"also\", \"always\", \"always\", \"always\", \"always\", \"amaze\", \"amaze\", \"amaze\", \"amaze\", \"and\", \"and\", \"and\", \"and\", \"appetite\", \"appetite\", \"appetite\", \"appetite\", \"apple\", \"apple\", \"apple\", \"apple\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"ask\", \"ask\", \"ask\", \"ask\", \"assortment\", \"assortment\", \"assortment\", \"assortment\", \"au\", \"au\", \"au\", \"au\", \"auto\", \"auto\", \"auto\", \"auto\", \"back\", \"back\", \"back\", \"back\", \"bad\", \"bad\", \"bad\", \"bad\", \"bagel\", \"bagel\", \"bagel\", \"bagel\", \"barber\", \"barber\", \"barber\", \"barber\", \"be\", \"be\", \"be\", \"be\", \"bed\", \"bed\", \"bed\", \"bed\", \"benedict\", \"benedict\", \"benedict\", \"benedict\", \"big\", \"big\", \"big\", \"big\", \"booze\", \"booze\", \"booze\", \"booze\", \"brisket\", \"brisket\", \"brisket\", \"brisket\", \"brunch\", \"brunch\", \"brunch\", \"brunch\", \"bucket\", \"bucket\", \"bucket\", \"bucket\", \"buffalo\", \"buffalo\", \"buffalo\", \"buffalo\", \"buffet\", \"buffet\", \"buffet\", \"buffet\", \"burn\", \"burn\", \"burn\", \"burn\", \"cab\", \"cab\", \"cab\", \"cab\", \"cappuccino\", \"cappuccino\", \"cappuccino\", \"cappuccino\", \"car\", \"car\", \"car\", \"car\", \"carne\", \"carne\", \"carne\", \"carne\", \"cart\", \"cart\", \"cart\", \"cart\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"cheesy\", \"cheesy\", \"cheesy\", \"cheesy\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"choice\", \"choice\", \"choice\", \"choice\", \"chorizo\", \"chorizo\", \"chorizo\", \"chorizo\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"combination\", \"combination\", \"combination\", \"combination\", \"come\", \"come\", \"come\", \"come\", \"company\", \"company\", \"company\", \"company\", \"convenience\", \"convenience\", \"convenience\", \"convenience\", \"cost\", \"cost\", \"cost\", \"cost\", \"could\", \"could\", \"could\", \"could\", \"damage\", \"damage\", \"damage\", \"damage\", \"damn\", \"damn\", \"damn\", \"damn\", \"de\", \"de\", \"de\", \"de\", \"dealer\", \"dealer\", \"dealer\", \"dealer\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"deli\", \"deli\", \"deli\", \"deli\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"dental\", \"dental\", \"dental\", \"dental\", \"diamond\", \"diamond\", \"diamond\", \"diamond\", \"didn\", \"didn\", \"didn\", \"didn\", \"dish\", \"dish\", \"dish\", \"dish\", \"do\", \"do\", \"do\", \"do\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"dog\", \"dog\", \"dog\", \"dog\", \"drink\", \"drink\", \"drink\", \"drink\", \"dumpling\", \"dumpling\", \"dumpling\", \"dumpling\", \"eat\", \"eat\", \"eat\", \"eat\", \"egg\", \"egg\", \"egg\", \"egg\", \"eggplant\", \"eggplant\", \"eggplant\", \"eggplant\", \"en\", \"en\", \"en\", \"en\", \"est\", \"est\", \"est\", \"est\", \"et\", \"et\", \"et\", \"et\", \"even\", \"even\", \"even\", \"even\", \"every\", \"every\", \"every\", \"every\", \"exceed\", \"exceed\", \"exceed\", \"exceed\", \"experience\", \"experience\", \"experience\", \"experience\", \"facial\", \"facial\", \"facial\", \"facial\", \"family\", \"family\", \"family\", \"family\", \"fav\", \"fav\", \"fav\", \"fav\", \"find\", \"find\", \"find\", \"find\", \"food\", \"food\", \"food\", \"food\", \"for\", \"for\", \"for\", \"for\", \"fry\", \"fry\", \"fry\", \"fry\", \"gentle\", \"gentle\", \"gentle\", \"gentle\", \"get\", \"get\", \"get\", \"get\", \"glass\", \"glass\", \"glass\", \"glass\", \"go\", \"go\", \"go\", \"go\", \"golden\", \"golden\", \"golden\", \"golden\", \"golf\", \"golf\", \"golf\", \"golf\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"great\", \"green\", \"green\", \"green\", \"green\", \"groupon\", \"groupon\", \"groupon\", \"groupon\", \"guy\", \"guy\", \"guy\", \"guy\", \"hair\", \"hair\", \"hair\", \"hair\", \"have\", \"have\", \"have\", \"have\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"how\", \"how\", \"how\", \"how\", \"hr\", \"hr\", \"hr\", \"hr\", \"in\", \"in\", \"in\", \"in\", \"insist\", \"insist\", \"insist\", \"insist\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"job\", \"job\", \"job\", \"job\", \"la\", \"la\", \"la\", \"la\", \"le\", \"le\", \"le\", \"le\", \"les\", \"les\", \"les\", \"les\", \"like\", \"like\", \"like\", \"like\", \"location\", \"location\", \"location\", \"location\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"lose\", \"lose\", \"lose\", \"lose\", \"love\", \"love\", \"love\", \"love\", \"make\", \"make\", \"make\", \"make\", \"mall\", \"mall\", \"mall\", \"mall\", \"manager\", \"manager\", \"manager\", \"manager\", \"mango\", \"mango\", \"mango\", \"mango\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"manner\", \"manner\", \"manner\", \"manner\", \"maple\", \"maple\", \"maple\", \"maple\", \"margarita\", \"margarita\", \"margarita\", \"margarita\", \"market\", \"market\", \"market\", \"market\", \"martini\", \"martini\", \"martini\", \"martini\", \"mayo\", \"mayo\", \"mayo\", \"mayo\", \"menu\", \"menu\", \"menu\", \"menu\", \"mushroom\", \"mushroom\", \"mushroom\", \"mushroom\", \"mussel\", \"mussel\", \"mussel\", \"mussel\", \"must\", \"must\", \"must\", \"must\", \"need\", \"need\", \"need\", \"need\", \"never\", \"never\", \"never\", \"never\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"noodle\", \"noodle\", \"noodle\", \"noodle\", \"north\", \"north\", \"north\", \"north\", \"not\", \"not\", \"not\", \"not\", \"notice\", \"notice\", \"notice\", \"notice\", \"of\", \"of\", \"of\", \"of\", \"office\", \"office\", \"office\", \"office\", \"omelette\", \"omelette\", \"omelette\", \"omelette\", \"on\", \"on\", \"on\", \"on\", \"one\", \"one\", \"one\", \"one\", \"operate\", \"operate\", \"operate\", \"operate\", \"order\", \"order\", \"order\", \"order\", \"other\", \"other\", \"other\", \"other\", \"owner\", \"owner\", \"owner\", \"owner\", \"park\", \"park\", \"park\", \"park\", \"pastor\", \"pastor\", \"pastor\", \"pastor\", \"pedicure\", \"pedicure\", \"pedicure\", \"pedicure\", \"people\", \"people\", \"people\", \"people\", \"pepper\", \"pepper\", \"pepper\", \"pepper\", \"pepperoni\", \"pepperoni\", \"pepperoni\", \"pepperoni\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"personality\", \"personality\", \"personality\", \"personality\", \"phoenix\", \"phoenix\", \"phoenix\", \"phoenix\", \"pick\", \"pick\", \"pick\", \"pick\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"place\", \"place\", \"place\", \"place\", \"plumbing\", \"plumbing\", \"plumbing\", \"plumbing\", \"pork\", \"pork\", \"pork\", \"pork\", \"practice\", \"practice\", \"practice\", \"practice\", \"preference\", \"preference\", \"preference\", \"preference\", \"press\", \"press\", \"press\", \"press\", \"price\", \"price\", \"price\", \"price\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"pub\", \"pub\", \"pub\", \"pub\", \"pull\", \"pull\", \"pull\", \"pull\", \"que\", \"que\", \"que\", \"que\", \"reach\", \"reach\", \"reach\", \"reach\", \"really\", \"really\", \"really\", \"really\", \"receptionist\", \"receptionist\", \"receptionist\", \"receptionist\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"record\", \"record\", \"record\", \"record\", \"refuse\", \"refuse\", \"refuse\", \"refuse\", \"repair\", \"repair\", \"repair\", \"repair\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"rise\", \"rise\", \"rise\", \"rise\", \"roll\", \"roll\", \"roll\", \"roll\", \"salad\", \"salad\", \"salad\", \"salad\", \"sample\", \"sample\", \"sample\", \"sample\", \"saturday\", \"saturday\", \"saturday\", \"saturday\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"say\", \"say\", \"say\", \"say\", \"scratch\", \"scratch\", \"scratch\", \"scratch\", \"sear\", \"sear\", \"sear\", \"sear\", \"service\", \"service\", \"service\", \"service\", \"shuttle\", \"shuttle\", \"shuttle\", \"shuttle\", \"sister\", \"sister\", \"sister\", \"sister\", \"smart\", \"smart\", \"smart\", \"smart\", \"smoothie\", \"smoothie\", \"smoothie\", \"smoothie\", \"so\", \"so\", \"so\", \"so\", \"soft\", \"soft\", \"soft\", \"soft\", \"staff\", \"staff\", \"staff\", \"staff\", \"study\", \"study\", \"study\", \"study\", \"sub\", \"sub\", \"sub\", \"sub\", \"super\", \"super\", \"super\", \"super\", \"taco\", \"taco\", \"taco\", \"taco\", \"take\", \"take\", \"take\", \"take\", \"tasteless\", \"tasteless\", \"tasteless\", \"tasteless\", \"tell\", \"tell\", \"tell\", \"tell\", \"that\", \"that\", \"that\", \"that\", \"the\", \"the\", \"the\", \"the\", \"there\", \"there\", \"there\", \"there\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"this\", \"this\", \"this\", \"this\", \"tight\", \"tight\", \"tight\", \"tight\", \"time\", \"time\", \"time\", \"time\", \"to\", \"to\", \"to\", \"to\", \"today\", \"today\", \"today\", \"today\", \"tofu\", \"tofu\", \"tofu\", \"tofu\", \"ton\", \"ton\", \"ton\", \"ton\", \"try\", \"try\", \"try\", \"try\", \"um\", \"um\", \"um\", \"um\", \"un\", \"un\", \"un\", \"un\", \"use\", \"use\", \"use\", \"use\", \"ve\", \"ve\", \"ve\", \"ve\", \"vegetarian\", \"vegetarian\", \"vegetarian\", \"vegetarian\", \"very\", \"very\", \"very\", \"very\", \"vet\", \"vet\", \"vet\", \"vet\", \"wait\", \"wait\", \"wait\", \"wait\", \"want\", \"want\", \"want\", \"want\", \"welcoming\", \"welcoming\", \"welcoming\", \"welcoming\", \"well\", \"well\", \"well\", \"well\", \"with\", \"with\", \"with\", \"with\", \"work\", \"work\", \"work\", \"work\", \"would\", \"would\", \"would\", \"would\", \"yellow\", \"yellow\", \"yellow\", \"yellow\", \"yesterday\", \"yesterday\", \"yesterday\", \"yesterday\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 4, 1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el867891166011112008339650492\", ldavis_el867891166011112008339650492_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el867891166011112008339650492\", ldavis_el867891166011112008339650492_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el867891166011112008339650492\", ldavis_el867891166011112008339650492_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.008664 -0.003365       1        1  28.514338\n",
       "3      0.009272 -0.001199       2        1  28.127855\n",
       "0      0.001002 -0.004091       3        1  22.150257\n",
       "1     -0.001610  0.008655       4        1  21.207546, topic_info=    Category          Freq        Term         Total  loglift  logprob\n",
       "0    Default  32158.000000      -PRON-  32158.000000  30.0000  30.0000\n",
       "33   Default  26046.000000         the  26046.000000  29.0000  29.0000\n",
       "4    Default  18316.000000          be  18316.000000  28.0000  28.0000\n",
       "44   Default   6289.000000        good   6289.000000  27.0000  27.0000\n",
       "134  Default   5316.000000       place   5316.000000  26.0000  26.0000\n",
       "208  Default   4243.000000       great   4243.000000  25.0000  25.0000\n",
       "14   Default   6316.000000        have   6316.000000  24.0000  24.0000\n",
       "197  Default   3005.000000        back   3005.000000  23.0000  23.0000\n",
       "88   Default   3186.000000        make   3186.000000  22.0000  22.0000\n",
       "362  Default   3493.000000       order   3493.000000  21.0000  21.0000\n",
       "96   Default   3648.000000         one   3648.000000  20.0000  20.0000\n",
       "13   Default   6225.000000         get   6225.000000  19.0000  19.0000\n",
       "348  Default   1642.000000        find   1642.000000  18.0000  18.0000\n",
       "76   Default   5704.000000          go   5704.000000  17.0000  17.0000\n",
       "343  Default    905.000000        dish    905.000000  16.0000  16.0000\n",
       "836  Default   1094.000000         use   1094.000000  15.0000  15.0000\n",
       "34   Default   4334.000000        time   4334.000000  14.0000  14.0000\n",
       "184  Default   1344.000000        menu   1344.000000  13.0000  13.0000\n",
       "118  Default   2647.000000        well   2647.000000  12.0000  12.0000\n",
       "297  Default   1288.000000       thing   1288.000000  11.0000  11.0000\n",
       "186  Default   2708.000000      really   2708.000000  10.0000  10.0000\n",
       "17   Default   3912.000000        like   3912.000000   9.0000   9.0000\n",
       "396  Default   1565.000000         ask   1565.000000   8.0000   8.0000\n",
       "332  Default    868.000000      cheese    868.000000   7.0000   7.0000\n",
       "40   Default   3996.000000        come   3996.000000   6.0000   6.0000\n",
       "187  Default   1407.000000   recommend   1407.000000   5.0000   5.0000\n",
       "462  Default    591.000000        roll    591.000000   4.0000   4.0000\n",
       "138  Default   1351.000000       there   1351.000000   3.0000   3.0000\n",
       "38   Default   1048.000000        with   1048.000000   2.0000   2.0000\n",
       "286  Default   1115.000000       other   1115.000000   1.0000   1.0000\n",
       "..       ...           ...         ...           ...      ...      ...\n",
       "14    Topic4   1536.370117        have   6316.891602   0.1370  -4.4687\n",
       "822   Topic4    346.745850         new   1213.367188   0.2983  -5.9573\n",
       "138   Topic4    377.271118       there   1351.506592   0.2748  -5.8729\n",
       "161   Topic4    493.795776       price   1839.448486   0.2357  -5.6038\n",
       "263   Topic4    405.148712  experience   1480.738892   0.2548  -5.8016\n",
       "11    Topic4    404.798248       could   1490.035278   0.2476  -5.8025\n",
       "3     Topic4    591.139893        also   2304.161133   0.1904  -5.4238\n",
       "33    Topic4   4829.433105         the  26046.742188  -0.1344  -3.3234\n",
       "49    Topic4    911.589294     service   3839.165039   0.1130  -4.9907\n",
       "40    Topic4    925.975952        come   3996.614258   0.0885  -4.9750\n",
       "187   Topic4    381.410126   recommend   1407.983032   0.2448  -5.8620\n",
       "37    Topic4    452.677979        wait   1736.952393   0.2061  -5.6907\n",
       "4     Topic4   3201.159912          be  18316.896484  -0.1935  -3.7346\n",
       "17    Topic4    886.369629        like   3912.314941   0.0661  -5.0188\n",
       "307   Topic4    651.456421         and   2726.291016   0.1193  -5.3267\n",
       "13    Topic4   1221.378540         get   6225.294922  -0.0778  -4.6982\n",
       "76    Topic4   1086.152222          go   5704.487305  -0.1078  -4.8155\n",
       "150   Topic4    942.031250        food   5113.013672  -0.1407  -4.9579\n",
       "186   Topic4    597.571777      really   2708.294922   0.0396  -5.4130\n",
       "208   Topic4    782.546753       great   4243.268555  -0.1397  -5.1433\n",
       "21    Topic4    478.672943        look   1995.973022   0.1229  -5.6349\n",
       "30    Topic4    554.656921         say   2571.212158   0.0170  -5.4875\n",
       "44    Topic4    943.098145        good   6289.851562  -0.3467  -4.9567\n",
       "35    Topic4    704.334534          to   4101.755371  -0.2111  -5.2486\n",
       "36    Topic4    535.240540         try   2604.539795  -0.0315  -5.5232\n",
       "137   Topic4    516.641174        take   2493.612305  -0.0233  -5.5585\n",
       "39    Topic4    579.486023       would   3240.399902  -0.1705  -5.4438\n",
       "134   Topic4    687.362000       place   5316.274414  -0.4949  -5.2730\n",
       "218   Topic4    529.155396         not   3635.725586  -0.3765  -5.5346\n",
       "197   Topic4    483.320312        back   3005.944824  -0.2769  -5.6252\n",
       "\n",
       "[342 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "0         1  0.213290     -PRON-\n",
       "0         2  0.351544     -PRON-\n",
       "0         3  0.212761     -PRON-\n",
       "0         4  0.222401     -PRON-\n",
       "2         1  0.231922        all\n",
       "2         2  0.325022        all\n",
       "2         3  0.266628        all\n",
       "2         4  0.176283        all\n",
       "3         1  0.272984       also\n",
       "3         2  0.309006       also\n",
       "3         3  0.161447       also\n",
       "3         4  0.256492       also\n",
       "613       1  0.360039     always\n",
       "613       2  0.332187     always\n",
       "613       3  0.182737     always\n",
       "613       4  0.124995     always\n",
       "1242      1  0.488468      amaze\n",
       "1242      2  0.195387      amaze\n",
       "1242      3  0.244234      amaze\n",
       "1242      4  0.081411      amaze\n",
       "307       1  0.219712        and\n",
       "307       2  0.326451        and\n",
       "307       3  0.214577        and\n",
       "307       4  0.238786        and\n",
       "2424      1  0.234787   appetite\n",
       "2424      2  0.195656   appetite\n",
       "2424      3  0.195656   appetite\n",
       "2424      4  0.352181   appetite\n",
       "1132      1  0.492096      apple\n",
       "1132      2  0.168033      apple\n",
       "...     ...       ...        ...\n",
       "300       3  0.252348       want\n",
       "300       4  0.220938       want\n",
       "979       1  0.454782  welcoming\n",
       "979       2  0.303188  welcoming\n",
       "979       3  0.151594  welcoming\n",
       "979       4  0.086625  welcoming\n",
       "118       1  0.314631       well\n",
       "118       2  0.272705       well\n",
       "118       3  0.133709       well\n",
       "118       4  0.279126       well\n",
       "38        1  0.200280       with\n",
       "38        2  0.241289       with\n",
       "38        3  0.249873       with\n",
       "38        4  0.308049       with\n",
       "321       1  0.214889       work\n",
       "321       2  0.373090       work\n",
       "321       3  0.265645       work\n",
       "321       4  0.146995       work\n",
       "39        1  0.249661      would\n",
       "39        2  0.317862      would\n",
       "39        3  0.253981      would\n",
       "39        4  0.178682      would\n",
       "2165      1  0.203323     yellow\n",
       "2165      2  0.243988     yellow\n",
       "2165      3  0.182991     yellow\n",
       "2165      4  0.365982     yellow\n",
       "389       1  0.424346  yesterday\n",
       "389       2  0.235748  yesterday\n",
       "389       3  0.129661  yesterday\n",
       "389       4  0.200386  yesterday\n",
       "\n",
       "[892 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 4, 1, 2])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "In the LDAvis whitepaper (ref: https://www.aclweb.org/anthology/W14-3110), it is stated\n",
    "that topic inferred by LDA are not always easily interpretable to humans. Unfortunately such is\n",
    "the case here, as I am not able to make any definitive conclusions on the basis of my topic model. \n",
    "It would appear the topics contain positive descriptors, indicating that positive reviews are \n",
    "in the majority in the dataset. Food and service are also referenced often meaning those are often \n",
    "discussed in the processed reviews. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "u4-s1-nlp"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
