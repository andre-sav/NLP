{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import squarify\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Optional:* Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description\n",
    "\n",
    "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/job_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['description', 'title'], dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    import re\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.description = df.description.replace(r'\\\\n',' ', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Job Requirements: Conceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role) Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL/Hive or similar programming language Must show past work via GitHub, Kaggle or any other published article Master\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field. Apply Now\"'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (b\"Job, Requirements:\\nConceptual, understandi...\n",
       "1      (b'Job, Description\\n\\nAs, a, Data, Scientist,...\n",
       "2      (b'As, a, Data, Scientist, you, will, be, work...\n",
       "3      (b'$4,969, -, $, 6,756, a, monthContractUnder,...\n",
       "4      (b'Location, :, USA, \\xe2\\x80\\x93, multiple, l...\n",
       "5      (b'Create, various, Business, Intelligence, An...\n",
       "6      (b'As, Spotify, Premium, swells, to, over, 96,...\n",
       "7      (b\"Everytown, for, Gun, Safety, ,, the, nation...\n",
       "8      (b\"MS, in, a, quantitative, discipline, such, ...\n",
       "9      (b'Slack, is, hiring, experienced, data, scien...\n",
       "10     (b'Who, We, Are\\nBlackThorn, Therapeutics, is,...\n",
       "11     (b'Part, -, timeAbout, The, Opportunity\\nHere,...\n",
       "12     (b\"nfosys\\xe2\\x80\\x93, Data, &, amp, ;, Analyt...\n",
       "13     (b'As, Spotify, Premium, swells, to, over, 96,...\n",
       "14     (b'Experience, with, guiding, R&amp;D, strateg...\n",
       "15     (b'The, Atlantic, is, seeking, a, Data, Scient...\n",
       "16     (b'THE, CHALLENGE\\nEventbrite, is, big, ,, bus...\n",
       "17     (b'ContractWe, are, looking, to, hire, for, a,...\n",
       "18     (b\"Everytown, for, Gun, Safety, ,, the, nation...\n",
       "19     (b'$70,000, -, $, 100,000, a, yearTitle, :, Da...\n",
       "20     (b'$45,000, a, yearWorking, under, direction, ...\n",
       "21     (b'The, Challenge:\\nAre, you, excited, at, the...\n",
       "22     (b'We, are, seeking, a, Data, Scientist, to, j...\n",
       "23     (b'Motiion, is, a, technology, and, data, comp...\n",
       "24     (b'The, Scientist, is, responsible, for, the, ...\n",
       "25     (b\"As, a, Data, Scientist, for, Ads, Measureme...\n",
       "26     (b'Summary\\nPosted, :, Mar, 6, ,, 2019\\nWeekly...\n",
       "27     (b'Slack, is, looking, for, experienced, data,...\n",
       "28     (b\"nfosys\\xe2\\x80\\x93, Data, &, amp, ;, Analyt...\n",
       "29     (b'Part, -, time, ,, InternshipSUMMARY:\\n\\n\\nS...\n",
       "                             ...                        \n",
       "396    (b\"ABOUT, US\\nLark, is, the, world, 's, larges...\n",
       "397    (b'Zenreach, solves, a, major, problem, for, b...\n",
       "398    (b'Position, Description\\nAs, the, Walmart, Vo...\n",
       "399    (b'By, trade, we, are, a, technology, company,...\n",
       "400    (b'Purpose, &, amp, ;, Overall, Relevance, for...\n",
       "401    (b\"about, dscout\\nWe, are, dscout, ., At, our,...\n",
       "402    (b\"Junior, Data, Scientist, -, Big, Data, (, E...\n",
       "403    (b\"About, Us\\nInterested, in, working, for, a,...\n",
       "404    (b'Air, Products, ,, Inc., ,, a, Fortune, 500,...\n",
       "405    (b\"Data, Scientist, -\\nDo, you, want, the, opp...\n",
       "406    (b'Job, Description:\\nData, Scientist\\nInterac...\n",
       "407    (b'The, Data, Scientist, I, mines, and, analyz...\n",
       "408    (b'FinLocker, is, a, leading, financial, data,...\n",
       "409    (b'With, annual, sales, of, $, 15, billion, ,,...\n",
       "410    (b'Job, Description:\\n\\nThe, Enterprise, Data,...\n",
       "411    (b\"Description:\\nChicago, -, IL, ,, IL150SW, ,...\n",
       "412    (b'Nike, Supply, Chain, experts, ensure, that,...\n",
       "413    (b'The, Principal, Data, Scientist, is, respon...\n",
       "414    (b'We, are, looking, for, a, Senior, Data, Sci...\n",
       "415    (b'Temporary, ,, Internship\\nThe, Marketing, D...\n",
       "416    (b'Los, Gatos, ,, California\\nScience, and, An...\n",
       "417    (b'About, the, Role, ..., \\n\\nLogic2020, is, l...\n",
       "418    (b'ContractThe, role, is, largely, operational...\n",
       "419    (b'Bachelor\\xe2\\x80\\x99s, or, Master\\xe2\\x80\\x...\n",
       "420    (b'At, Uber, ,, we, ignite, opportunity, by, s...\n",
       "421    (b\"About, Us:\\nWant, to, be, part, of, a, fant...\n",
       "422    (b'InternshipAt, Uber, ,, we, ignite, opportun...\n",
       "423    (b'$200,000, -, $, 350,000, a, yearA, million,...\n",
       "424    (b\"SENIOR, DATA, SCIENTIST\\nJOB, DESCRIPTION\\n...\n",
       "425    (b'Cerner, Intelligence, is, a, new, ,, innova...\n",
       "Name: description, Length: 426, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=0.05,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english', min_df=0.05, max_df=0.90)\n",
    "\n",
    "vect.fit(df.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.transform(df.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '10',\n",
       " '100',\n",
       " '2019',\n",
       " '40',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'academic',\n",
       " 'access',\n",
       " 'accommodation',\n",
       " 'accuracy',\n",
       " 'achieve',\n",
       " 'acquisition',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'activities',\n",
       " 'ad',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advertising',\n",
       " 'affirmative',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agile',\n",
       " 'ai',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'alongside',\n",
       " 'amazon',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'analyses',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analysts',\n",
       " 'analytic',\n",
       " 'analytical',\n",
       " 'analytics',\n",
       " 'analyze',\n",
       " 'analyzing',\n",
       " 'ancestry',\n",
       " 'answer',\n",
       " 'applicable',\n",
       " 'applicants',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'approach',\n",
       " 'approaches',\n",
       " 'appropriate',\n",
       " 'architecture',\n",
       " 'architectures',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'art',\n",
       " 'artificial',\n",
       " 'aspects',\n",
       " 'assess',\n",
       " 'assets',\n",
       " 'assigned',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'attention',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'automated',\n",
       " 'automation',\n",
       " 'available',\n",
       " 'aws',\n",
       " 'azure',\n",
       " 'bachelor',\n",
       " 'background',\n",
       " 'backgrounds',\n",
       " 'balance',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basis',\n",
       " 'bayesian',\n",
       " 'behavior',\n",
       " 'believe',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'best',\n",
       " 'better',\n",
       " 'bi',\n",
       " 'big',\n",
       " 'brand',\n",
       " 'brightest',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'broad',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'business',\n",
       " 'businesses',\n",
       " 'ca',\n",
       " 'campaigns',\n",
       " 'candidate',\n",
       " 'candidates',\n",
       " 'capabilities',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careers',\n",
       " 'causal',\n",
       " 'center',\n",
       " 'chain',\n",
       " 'challenge',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'characteristic',\n",
       " 'check',\n",
       " 'cities',\n",
       " 'citizenship',\n",
       " 'city',\n",
       " 'class',\n",
       " 'classification',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'client',\n",
       " 'clients',\n",
       " 'close',\n",
       " 'closely',\n",
       " 'cloud',\n",
       " 'clustering',\n",
       " 'code',\n",
       " 'coding',\n",
       " 'collaborate',\n",
       " 'collaboration',\n",
       " 'collaborative',\n",
       " 'colleagues',\n",
       " 'collection',\n",
       " 'color',\n",
       " 'com',\n",
       " 'combination',\n",
       " 'come',\n",
       " 'comfortable',\n",
       " 'commercial',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'common',\n",
       " 'communicate',\n",
       " 'communicating',\n",
       " 'communication',\n",
       " 'communications',\n",
       " 'communities',\n",
       " 'community',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'compensation',\n",
       " 'competitive',\n",
       " 'complete',\n",
       " 'complex',\n",
       " 'complexity',\n",
       " 'compliance',\n",
       " 'components',\n",
       " 'comprehensive',\n",
       " 'computational',\n",
       " 'computer',\n",
       " 'computing',\n",
       " 'concepts',\n",
       " 'conclusions',\n",
       " 'conduct',\n",
       " 'connect',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'considered',\n",
       " 'consistent',\n",
       " 'constantly',\n",
       " 'consulting',\n",
       " 'consumer',\n",
       " 'consumers',\n",
       " 'content',\n",
       " 'context',\n",
       " 'continuous',\n",
       " 'contribute',\n",
       " 'control',\n",
       " 'core',\n",
       " 'corporate',\n",
       " 'cost',\n",
       " 'countries',\n",
       " 'country',\n",
       " 'create',\n",
       " 'creating',\n",
       " 'creation',\n",
       " 'creative',\n",
       " 'criminal',\n",
       " 'critical',\n",
       " 'cross',\n",
       " 'culture',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'cutting',\n",
       " 'daily',\n",
       " 'dashboards',\n",
       " 'database',\n",
       " 'databases',\n",
       " 'datasets',\n",
       " 'day',\n",
       " 'decision',\n",
       " 'decisions',\n",
       " 'dedicated',\n",
       " 'deep',\n",
       " 'define',\n",
       " 'defining',\n",
       " 'degree',\n",
       " 'deliver',\n",
       " 'deliverables',\n",
       " 'delivering',\n",
       " 'delivery',\n",
       " 'demand',\n",
       " 'demonstrate',\n",
       " 'demonstrated',\n",
       " 'dental',\n",
       " 'department',\n",
       " 'deploy',\n",
       " 'deploying',\n",
       " 'deployment',\n",
       " 'depth',\n",
       " 'description',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'designing',\n",
       " 'desired',\n",
       " 'detection',\n",
       " 'develop',\n",
       " 'developers',\n",
       " 'developing',\n",
       " 'development',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'digital',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'disabilities',\n",
       " 'disability',\n",
       " 'discipline',\n",
       " 'discover',\n",
       " 'discriminate',\n",
       " 'disparate',\n",
       " 'distributed',\n",
       " 'distributions',\n",
       " 'diverse',\n",
       " 'diversity',\n",
       " 'document',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'domain',\n",
       " 'don',\n",
       " 'draw',\n",
       " 'drive',\n",
       " 'driven',\n",
       " 'drivers',\n",
       " 'driving',\n",
       " 'duties',\n",
       " 'dynamic',\n",
       " 'easy',\n",
       " 'ecommerce',\n",
       " 'econometrics',\n",
       " 'economics',\n",
       " 'ecosystem',\n",
       " 'edge',\n",
       " 'education',\n",
       " 'eeo',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'effectiveness',\n",
       " 'efficiency',\n",
       " 'efficient',\n",
       " 'efficiently',\n",
       " 'efforts',\n",
       " 'eligible',\n",
       " 'employee',\n",
       " 'employees',\n",
       " 'employer',\n",
       " 'employment',\n",
       " 'empower',\n",
       " 'enable',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'engagement',\n",
       " 'engineer',\n",
       " 'engineering',\n",
       " 'engineers',\n",
       " 'enhance',\n",
       " 'enjoy',\n",
       " 'ensure',\n",
       " 'enterprise',\n",
       " 'environment',\n",
       " 'environments',\n",
       " 'equal',\n",
       " 'equivalent',\n",
       " 'essential',\n",
       " 'establish',\n",
       " 'etl',\n",
       " 'evaluate',\n",
       " 'evaluation',\n",
       " 'events',\n",
       " 'evolve',\n",
       " 'example',\n",
       " 'excel',\n",
       " 'excellence',\n",
       " 'excellent',\n",
       " 'exceptional',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'execute',\n",
       " 'execution',\n",
       " 'existing',\n",
       " 'expand',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'experiences',\n",
       " 'experiment',\n",
       " 'experimental',\n",
       " 'experimentation',\n",
       " 'experiments',\n",
       " 'expert',\n",
       " 'expertise',\n",
       " 'experts',\n",
       " 'explain',\n",
       " 'exploration',\n",
       " 'exploratory',\n",
       " 'explore',\n",
       " 'expression',\n",
       " 'external',\n",
       " 'extract',\n",
       " 'extraction',\n",
       " 'facing',\n",
       " 'fair',\n",
       " 'familiarity',\n",
       " 'family',\n",
       " 'fast',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'federal',\n",
       " 'feedback',\n",
       " 'field',\n",
       " 'finance',\n",
       " 'financial',\n",
       " 'finding',\n",
       " 'findings',\n",
       " 'fit',\n",
       " 'flexible',\n",
       " 'focus',\n",
       " 'focused',\n",
       " 'following',\n",
       " 'forecasting',\n",
       " 'form',\n",
       " 'fortune',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'frameworks',\n",
       " 'francisco',\n",
       " 'free',\n",
       " 'fun',\n",
       " 'function',\n",
       " 'functional',\n",
       " 'functions',\n",
       " 'future',\n",
       " 'gain',\n",
       " 'gathering',\n",
       " 'gender',\n",
       " 'general',\n",
       " 'generate',\n",
       " 'generation',\n",
       " 'genetic',\n",
       " 'given',\n",
       " 'global',\n",
       " 'goal',\n",
       " 'goals',\n",
       " 'good',\n",
       " 'google',\n",
       " 'government',\n",
       " 'graduate',\n",
       " 'great',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'grow',\n",
       " 'growing',\n",
       " 'growth',\n",
       " 'guidance',\n",
       " 'guide',\n",
       " 'hadoop',\n",
       " 'hands',\n",
       " 'hard',\n",
       " 'health',\n",
       " 'healthcare',\n",
       " 'help',\n",
       " 'helping',\n",
       " 'helps',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'hire',\n",
       " 'hive',\n",
       " 'hoc',\n",
       " 'hours',\n",
       " 'human',\n",
       " 'hypothesis',\n",
       " 'ideal',\n",
       " 'ideas',\n",
       " 'identify',\n",
       " 'identifying',\n",
       " 'identity',\n",
       " 'impact',\n",
       " 'impactful',\n",
       " 'implement',\n",
       " 'implementation',\n",
       " 'implementing',\n",
       " 'important',\n",
       " 'improve',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'improving',\n",
       " 'include',\n",
       " 'includes',\n",
       " 'including',\n",
       " 'inclusive',\n",
       " 'increase',\n",
       " 'independent',\n",
       " 'independently',\n",
       " 'individual',\n",
       " 'individuals',\n",
       " 'industrial',\n",
       " 'industry',\n",
       " 'inference',\n",
       " 'influence',\n",
       " 'inform',\n",
       " 'information',\n",
       " 'infrastructure',\n",
       " 'initiatives',\n",
       " 'innovating',\n",
       " 'innovation',\n",
       " 'innovative',\n",
       " 'insight',\n",
       " 'insights',\n",
       " 'insurance',\n",
       " 'integrate',\n",
       " 'integration',\n",
       " 'integrity',\n",
       " 'intelligence',\n",
       " 'intern',\n",
       " 'internal',\n",
       " 'internship',\n",
       " 'interpersonal',\n",
       " 'interpret',\n",
       " 'issues',\n",
       " 'java',\n",
       " 'job',\n",
       " 'join',\n",
       " 'journey',\n",
       " 'just',\n",
       " 'keras',\n",
       " 'key',\n",
       " 'know',\n",
       " 'knowledge',\n",
       " 'language',\n",
       " 'languages',\n",
       " 'large',\n",
       " 'largest',\n",
       " 'latest',\n",
       " 'law',\n",
       " 'laws',\n",
       " 'lead',\n",
       " 'leader',\n",
       " 'leaders',\n",
       " 'leadership',\n",
       " 'leading',\n",
       " 'learn',\n",
       " 'learning',\n",
       " 'leave',\n",
       " 'legally',\n",
       " 'let',\n",
       " 'level',\n",
       " 'levels',\n",
       " 'leverage',\n",
       " 'leveraging',\n",
       " 'libraries',\n",
       " 'life',\n",
       " 'lifecycle',\n",
       " 'like',\n",
       " 'limited',\n",
       " 'line',\n",
       " 'linear',\n",
       " 'linux',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'll',\n",
       " 'local',\n",
       " 'location',\n",
       " 'locations',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'love',\n",
       " 'machine',\n",
       " 'maintain',\n",
       " 'major',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'manage',\n",
       " 'management',\n",
       " 'managers',\n",
       " 'managing',\n",
       " 'manipulate',\n",
       " 'manipulating',\n",
       " 'manner',\n",
       " 'marital',\n",
       " 'market',\n",
       " 'marketing',\n",
       " 'markets',\n",
       " 'master',\n",
       " 'masters',\n",
       " 'math',\n",
       " 'mathematical',\n",
       " 'mathematics',\n",
       " 'matlab',\n",
       " 'matter',\n",
       " 'meaningful',\n",
       " 'means',\n",
       " 'measure',\n",
       " 'measurement',\n",
       " 'media',\n",
       " 'medical',\n",
       " 'meet',\n",
       " 'member',\n",
       " 'members',\n",
       " 'methodologies',\n",
       " 'methods',\n",
       " 'metrics',\n",
       " 'microsoft',\n",
       " 'million',\n",
       " 'millions',\n",
       " 'minds',\n",
       " 'minimum',\n",
       " 'mining',\n",
       " 'mission',\n",
       " 'ml',\n",
       " 'mobile',\n",
       " 'model',\n",
       " 'modeling',\n",
       " 'models',\n",
       " 'modern',\n",
       " 'money',\n",
       " 'monitor',\n",
       " 'monitoring',\n",
       " 'motivated',\n",
       " 'moving',\n",
       " 'ms',\n",
       " 'multi',\n",
       " 'multiple',\n",
       " 'n2',\n",
       " 'n3',\n",
       " 'n4',\n",
       " 'n5',\n",
       " 'na',\n",
       " 'nability',\n",
       " 'nabout',\n",
       " 'nadditional',\n",
       " 'nadvanced',\n",
       " 'nall',\n",
       " 'napply',\n",
       " 'nas',\n",
       " 'nat',\n",
       " 'national',\n",
       " 'natural',\n",
       " 'nbachelor',\n",
       " 'nbasic',\n",
       " 'nbe',\n",
       " 'nbenefits',\n",
       " 'nbuild',\n",
       " 'ncollaborate',\n",
       " 'ncommunicate',\n",
       " 'ncompany',\n",
       " 'nconduct',\n",
       " 'ncreate',\n",
       " 'ndata',\n",
       " 'ndeep',\n",
       " 'ndemonstrated',\n",
       " 'ndesign',\n",
       " 'ndesired',\n",
       " 'ndevelop',\n",
       " 'necessary',\n",
       " 'neducation',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needs',\n",
       " 'network',\n",
       " 'networks',\n",
       " 'neural',\n",
       " 'new',\n",
       " 'nexcellent',\n",
       " 'nexperience',\n",
       " 'nexpertise',\n",
       " 'nfamiliarity',\n",
       " 'ngood',\n",
       " 'nidentify',\n",
       " 'nif',\n",
       " 'nin',\n",
       " 'njob',\n",
       " 'nkey',\n",
       " 'nknowledge',\n",
       " 'nlead',\n",
       " 'nlp',\n",
       " 'nmaster',\n",
       " 'nminimum',\n",
       " 'nms',\n",
       " 'nmust',\n",
       " 'non',\n",
       " 'nosql',\n",
       " 'nour',\n",
       " 'novel',\n",
       " 'npartner',\n",
       " 'nperform',\n",
       " 'nphd',\n",
       " 'nposition',\n",
       " 'npreferred',\n",
       " 'nprimary',\n",
       " 'nproficiency',\n",
       " 'nproven',\n",
       " 'nprovide',\n",
       " 'nqualifications',\n",
       " 'nrequired',\n",
       " 'nrequirements',\n",
       " 'nresponsibilities',\n",
       " 'nself',\n",
       " 'nskills',\n",
       " 'nstrong',\n",
       " 'nthe',\n",
       " 'nthis',\n",
       " 'nto',\n",
       " 'numpy',\n",
       " 'nunderstanding',\n",
       " 'nuse',\n",
       " 'nwe',\n",
       " 'nwhat',\n",
       " 'nwho',\n",
       " 'nwork',\n",
       " 'nworking',\n",
       " 'nyou',\n",
       " 'nyour',\n",
       " 'objectives',\n",
       " 'offer',\n",
       " 'offers',\n",
       " 'office',\n",
       " 'ongoing',\n",
       " 'online',\n",
       " 'open',\n",
       " 'operate',\n",
       " 'operating',\n",
       " 'operational',\n",
       " 'operations',\n",
       " 'opportunities',\n",
       " 'opportunity',\n",
       " 'optimization',\n",
       " 'optimize',\n",
       " 'optimizing',\n",
       " 'oral',\n",
       " 'order',\n",
       " 'organization',\n",
       " 'organizational',\n",
       " 'organizations',\n",
       " 'orientation',\n",
       " 'oriented',\n",
       " 'origin',\n",
       " 'outcomes',\n",
       " 'outside',\n",
       " 'overview',\n",
       " 'paced',\n",
       " 'package',\n",
       " 'packages',\n",
       " 'paid',\n",
       " 'pandas',\n",
       " 'participate',\n",
       " 'partner',\n",
       " 'partners',\n",
       " 'party',\n",
       " 'passion',\n",
       " 'passionate',\n",
       " 'patterns',\n",
       " 'pay',\n",
       " 'peers',\n",
       " 'people',\n",
       " 'perform',\n",
       " 'performance',\n",
       " 'performing',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'perspectives',\n",
       " 'phd',\n",
       " 'physical',\n",
       " 'physics',\n",
       " 'pipeline',\n",
       " 'pipelines',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'planning',\n",
       " 'plans',\n",
       " 'platform',\n",
       " 'platforms',\n",
       " 'play',\n",
       " 'player',\n",
       " 'plus',\n",
       " 'points',\n",
       " 'policy',\n",
       " 'portfolio',\n",
       " 'position',\n",
       " 'positions',\n",
       " 'positive',\n",
       " 'possible',\n",
       " 'potential',\n",
       " 'power',\n",
       " 'practical',\n",
       " 'practices',\n",
       " 'predictive',\n",
       " 'preferably',\n",
       " 'preferred',\n",
       " 'pregnancy',\n",
       " 'present',\n",
       " 'presentation',\n",
       " 'presentations',\n",
       " 'presenting',\n",
       " 'pricing',\n",
       " 'primary',\n",
       " 'principles',\n",
       " 'priorities',\n",
       " 'prioritize',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'procedures',\n",
       " 'process',\n",
       " 'processes',\n",
       " 'processing',\n",
       " 'produce',\n",
       " 'product',\n",
       " 'production',\n",
       " 'products',\n",
       " 'professional',\n",
       " 'professionals',\n",
       " 'proficiency',\n",
       " 'program',\n",
       " 'programming',\n",
       " 'programs',\n",
       " 'project',\n",
       " 'projects',\n",
       " 'protected',\n",
       " 'proud',\n",
       " 'proven',\n",
       " 'provide',\n",
       " 'provider',\n",
       " 'provides',\n",
       " 'providing',\n",
       " 'public',\n",
       " 'purpose',\n",
       " 'python',\n",
       " 'qualifications',\n",
       " 'qualified',\n",
       " 'quality',\n",
       " 'quantitative',\n",
       " 'queries',\n",
       " 'querying',\n",
       " 'questions',\n",
       " 'quickly',\n",
       " 'race',\n",
       " 'random',\n",
       " 'range',\n",
       " 'rapidly',\n",
       " 'real',\n",
       " 'reasonable',\n",
       " 'receive',\n",
       " 'recognition',\n",
       " 'recognized',\n",
       " 'recommendation',\n",
       " 'recommendations',\n",
       " 'record',\n",
       " 'regard',\n",
       " 'regardless',\n",
       " 'regression',\n",
       " 'regular',\n",
       " 'related',\n",
       " 'relational',\n",
       " 'relationships',\n",
       " 'relevant',\n",
       " 'religion',\n",
       " 'report',\n",
       " 'reporting',\n",
       " 'reports',\n",
       " 'require',\n",
       " 'required',\n",
       " 'requirements',\n",
       " 'requires',\n",
       " 'research',\n",
       " 'resources',\n",
       " 'responsibilities',\n",
       " 'responsibility',\n",
       " 'responsible',\n",
       " 'results',\n",
       " 'retail',\n",
       " 'revenue',\n",
       " 'review',\n",
       " 'right',\n",
       " 'risk',\n",
       " 'robust',\n",
       " 'role',\n",
       " 'run',\n",
       " 'running',\n",
       " 'salary',\n",
       " 'sales',\n",
       " 'san',\n",
       " 'sas',\n",
       " 'save',\n",
       " 'scala',\n",
       " 'scalable',\n",
       " 'scale',\n",
       " 'science',\n",
       " 'sciences',\n",
       " 'scientific',\n",
       " 'scientist',\n",
       " 'scientists',\n",
       " 'scikit',\n",
       " 'scope',\n",
       " 'scripting',\n",
       " 'search',\n",
       " 'security',\n",
       " 'seek',\n",
       " 'seeking',\n",
       " 'segmentation',\n",
       " 'self',\n",
       " 'senior',\n",
       " 'series',\n",
       " 'serve',\n",
       " 'service',\n",
       " 'services',\n",
       " 'set',\n",
       " 'sets',\n",
       " 'setting',\n",
       " 'sex',\n",
       " 'sexual',\n",
       " 'shape',\n",
       " 'share',\n",
       " 'shopping',\n",
       " 'significant',\n",
       " 'similar',\n",
       " 'simple',\n",
       " 'simulation',\n",
       " 'skill',\n",
       " 'skills',\n",
       " 'small',\n",
       " 'social',\n",
       " 'software',\n",
       " 'solid',\n",
       " 'solution',\n",
       " 'solutions',\n",
       " 'solve',\n",
       " 'solving',\n",
       " 'sophisticated',\n",
       " 'source',\n",
       " 'sources',\n",
       " 'space',\n",
       " 'spark',\n",
       " 'specific',\n",
       " 'specifically',\n",
       " 'spirit',\n",
       " 'sql',\n",
       " 'stack',\n",
       " 'staff',\n",
       " 'stakeholders',\n",
       " 'standard',\n",
       " 'standards',\n",
       " 'starter',\n",
       " 'state',\n",
       " 'states',\n",
       " 'statistical',\n",
       " 'statistics',\n",
       " 'status',\n",
       " 'strategic',\n",
       " 'strategies',\n",
       " 'strategy',\n",
       " 'strive',\n",
       " 'strong',\n",
       " 'structure',\n",
       " 'structured',\n",
       " 'structures',\n",
       " 'study',\n",
       " 'subject',\n",
       " 'succeed',\n",
       " 'success',\n",
       " 'successful',\n",
       " 'successfully',\n",
       " 'suite',\n",
       " 'summary',\n",
       " 'supervised',\n",
       " 'supply',\n",
       " 'support',\n",
       " 'supporting',\n",
       " 'systems',\n",
       " 'tableau',\n",
       " 'talent',\n",
       " 'talented',\n",
       " 'targeting',\n",
       " 'tasks',\n",
       " 'team',\n",
       " 'teams',\n",
       " 'tech',\n",
       " 'technical',\n",
       " 'techniques',\n",
       " 'technologies',\n",
       " 'technology',\n",
       " 'tensorflow',\n",
       " 'term',\n",
       " 'test',\n",
       " 'testing',\n",
       " 'tests',\n",
       " 'text',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'thought',\n",
       " 'thousands',\n",
       " 'thrive',\n",
       " 'time',\n",
       " 'today',\n",
       " 'tool',\n",
       " 'tools',\n",
       " 'topics',\n",
       " 'track',\n",
       " 'training',\n",
       " 'transform',\n",
       " 'transformation',\n",
       " 'translate',\n",
       " 'travel',\n",
       " 'trees',\n",
       " 'trends',\n",
       " 'uncover',\n",
       " 'understand',\n",
       " 'understanding',\n",
       " 'unique',\n",
       " 'united',\n",
       " 'unstructured',\n",
       " 'unsupervised',\n",
       " 'usage',\n",
       " 'use',\n",
       " 'used',\n",
       " 'user',\n",
       " 'users',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'utilize',\n",
       " 'utilizing',\n",
       " 'vacation',\n",
       " 'validation',\n",
       " 'value',\n",
       " 'values',\n",
       " 'variety',\n",
       " 'various',\n",
       " 'varying',\n",
       " 'verbal',\n",
       " 'veteran',\n",
       " 'veterans',\n",
       " 'vision',\n",
       " 'visit',\n",
       " 'visualization',\n",
       " 'visualizations',\n",
       " 'want',\n",
       " 'way',\n",
       " 'ways',\n",
       " 'web',\n",
       " 'welcome',\n",
       " 'wide',\n",
       " 'work',\n",
       " 'workforce',\n",
       " 'working',\n",
       " 'workplace',\n",
       " 'works',\n",
       " 'world',\n",
       " 'write',\n",
       " 'writing',\n",
       " 'written',\n",
       " 'www',\n",
       " 'x80',\n",
       " 'x93',\n",
       " ...]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>2019</th>\n",
       "      <th>40</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>academic</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>x99</th>\n",
       "      <th>x99ll</th>\n",
       "      <th>x99re</th>\n",
       "      <th>x99s</th>\n",
       "      <th>x99t</th>\n",
       "      <th>x9d</th>\n",
       "      <th>xe2</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1010 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  100  2019  40  abilities  ability  able  academic  access  ...  \\\n",
       "0    0   0    0     0   0          0        1     0         0       0  ...   \n",
       "1    0   0    0     0   0          0        1     0         0       0  ...   \n",
       "2    0   0    0     0   0          0        0     0         0       0  ...   \n",
       "3    0   0    0     0   0          0        0     0         0       0  ...   \n",
       "4    0   0    0     0   0          0        0     0         0       0  ...   \n",
       "\n",
       "   x99  x99ll  x99re  x99s  x99t  x9d  xe2  year  years  york  \n",
       "0    0      0      0     0     0    0    0     0      0     0  \n",
       "1    2      0      2     2     0    0    8     1      0     0  \n",
       "2    0      0      0     0     0    0    0     0      0     0  \n",
       "3    0      0      0     0     0    0    0     1      0     0  \n",
       "4    0      0      0     0     0    0    1     0      1     0  \n",
       "\n",
       "[5 rows x 1010 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "df['tokens'] = df['description'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b\"Job, 1),\n",
       " (Requirements:, 1),\n",
       " (Conceptual, 1),\n",
       " (understanding, 1),\n",
       " (in, 1),\n",
       " (Machine, 1),\n",
       " (Learning, 1),\n",
       " (models, 1),\n",
       " (like, 1),\n",
       " (Nai\\xc2\\xa8ve, 1)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter()\n",
    "\n",
    "df['tokens'].apply(lambda x: word_counts.update(x))\n",
    "\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(docs):\n",
    "    word_counts = Counter()\n",
    "    appears_in = Counter()\n",
    "    \n",
    "    total_docs = len(docs)\n",
    "    \n",
    "    for doc in docs:\n",
    "        word_counts.update(doc)\n",
    "        appears_in.update(set(doc))\n",
    "    \n",
    "    temp = zip(word_counts.keys(), word_counts.values())\n",
    "    \n",
    "    wc = pd.DataFrame(temp, columns=['word','count'])\n",
    "    \n",
    "    wc['rank'] = wc['count'].rank(method='first',  ascending=False)\n",
    "    total = wc['count'].sum()\n",
    "    \n",
    "    wc['pct_total'] = wc['count'].apply(lambda x: x/total)\n",
    "    \n",
    "    wc = wc.sort_values(by='rank')\n",
    "    wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "    \n",
    "    t2 = zip(appears_in.keys(), appears_in.values())\n",
    "    ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "    wc = ac.merge(wc, on='word')\n",
    "    \n",
    "    wc['appears_in_pct'] = wc['appears_in'].apply(lambda x:  x/ total_docs)\n",
    "    \n",
    "    return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = count(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>appears_in</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_total</th>\n",
       "      <th>cul_pct_total</th>\n",
       "      <th>appears_in_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b\"Job</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Requirements:</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Conceptual</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>understanding</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Machine</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Learning</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>models</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>like</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Nai\\xc2\\xa8ve</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bayes,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>K-Means,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SVM,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Apriori,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Linear/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Regression,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Neural,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Random</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Forests,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Decision</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Trees,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>K-NN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>along</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>with</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hands-on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>experience</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>at</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>least</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208622</th>\n",
       "      <td>marital</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209142.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208973</th>\n",
       "      <td>status,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209143.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208902</th>\n",
       "      <td>veteran</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209144.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208645</th>\n",
       "      <td>status,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209145.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208809</th>\n",
       "      <td>age,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209146.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209160</th>\n",
       "      <td>disability,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209147.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209089</th>\n",
       "      <td>pregnancy,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209148.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208831</th>\n",
       "      <td>genetic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209149.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208995</th>\n",
       "      <td>information,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209150.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208738</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209151.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208667</th>\n",
       "      <td>status,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209152.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209017</th>\n",
       "      <td>sex,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209153.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208574</th>\n",
       "      <td>sexual</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209154.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208924</th>\n",
       "      <td>orientation,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209155.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208578</th>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209156.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208928</th>\n",
       "      <td>identity</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209157.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209093</th>\n",
       "      <td>or</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209158.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208835</th>\n",
       "      <td>any</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209159.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208763</th>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209160.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209114</th>\n",
       "      <td>legally</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209161.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208671</th>\n",
       "      <td>protected</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209162.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209021</th>\n",
       "      <td>category.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209163.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208950</th>\n",
       "      <td>Cerner</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209164.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208693</th>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209165.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208856</th>\n",
       "      <td>proud</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209166.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208599</th>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209167.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209137</th>\n",
       "      <td>be</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209168.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208879</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209169.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209044</th>\n",
       "      <td>drug-free</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209170.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208786</th>\n",
       "      <td>workplace.'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>209171.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209171 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  appears_in  count      rank  pct_total  cul_pct_total  \\\n",
       "19              b\"Job           1      1       1.0   0.000005       0.000005   \n",
       "101     Requirements:           1      1       2.0   0.000005       0.000010   \n",
       "92         Conceptual           1      1       3.0   0.000005       0.000014   \n",
       "56      understanding           1      1       4.0   0.000005       0.000019   \n",
       "47                 in           1      1       5.0   0.000005       0.000024   \n",
       "10            Machine           1      1       6.0   0.000005       0.000029   \n",
       "1            Learning           1      1       7.0   0.000005       0.000033   \n",
       "83             models           1      1       8.0   0.000005       0.000038   \n",
       "74               like           1      1       9.0   0.000005       0.000043   \n",
       "38      Nai\\xc2\\xa8ve           1      1      10.0   0.000005       0.000048   \n",
       "28             Bayes,           1      1      11.0   0.000005       0.000053   \n",
       "110          K-Means,           1      1      12.0   0.000005       0.000057   \n",
       "99               SVM,           1      1      13.0   0.000005       0.000062   \n",
       "64           Apriori,           1      1      14.0   0.000005       0.000067   \n",
       "54            Linear/           1      1      15.0   0.000005       0.000072   \n",
       "17           Logistic           1      1      16.0   0.000005       0.000076   \n",
       "8         Regression,           1      1      17.0   0.000005       0.000081   \n",
       "90            Neural,           1      1      18.0   0.000005       0.000086   \n",
       "81             Random           1      1      19.0   0.000005       0.000091   \n",
       "45           Forests,           1      1      20.0   0.000005       0.000096   \n",
       "36           Decision           1      1      21.0   0.000005       0.000100   \n",
       "117            Trees,           1      1      22.0   0.000005       0.000105   \n",
       "108              K-NN           1      1      23.0   0.000005       0.000110   \n",
       "72              along           1      1      24.0   0.000005       0.000115   \n",
       "62               with           1      1      25.0   0.000005       0.000120   \n",
       "26           hands-on           1      1      26.0   0.000005       0.000124   \n",
       "15         experience           1      1      27.0   0.000005       0.000129   \n",
       "97                 in           1      1      28.0   0.000005       0.000134   \n",
       "88                 at           1      1      29.0   0.000005       0.000139   \n",
       "52              least           1      1      30.0   0.000005       0.000143   \n",
       "...               ...         ...    ...       ...        ...            ...   \n",
       "208622        marital           1      1  209142.0   0.000005       0.999861   \n",
       "208973        status,           1      1  209143.0   0.000005       0.999866   \n",
       "208902        veteran           1      1  209144.0   0.000005       0.999871   \n",
       "208645        status,           1      1  209145.0   0.000005       0.999876   \n",
       "208809           age,           1      1  209146.0   0.000005       0.999880   \n",
       "209160    disability,           1      1  209147.0   0.000005       0.999885   \n",
       "209089     pregnancy,           1      1  209148.0   0.000005       0.999890   \n",
       "208831        genetic           1      1  209149.0   0.000005       0.999895   \n",
       "208995   information,           1      1  209150.0   0.000005       0.999900   \n",
       "208738    citizenship           1      1  209151.0   0.000005       0.999904   \n",
       "208667        status,           1      1  209152.0   0.000005       0.999909   \n",
       "209017           sex,           1      1  209153.0   0.000005       0.999914   \n",
       "208574         sexual           1      1  209154.0   0.000005       0.999919   \n",
       "208924   orientation,           1      1  209155.0   0.000005       0.999924   \n",
       "208578         gender           1      1  209156.0   0.000005       0.999928   \n",
       "208928       identity           1      1  209157.0   0.000005       0.999933   \n",
       "209093             or           1      1  209158.0   0.000005       0.999938   \n",
       "208835            any           1      1  209159.0   0.000005       0.999943   \n",
       "208763          other           1      1  209160.0   0.000005       0.999947   \n",
       "209114        legally           1      1  209161.0   0.000005       0.999952   \n",
       "208671      protected           1      1  209162.0   0.000005       0.999957   \n",
       "209021      category.           1      1  209163.0   0.000005       0.999962   \n",
       "208950         Cerner           1      1  209164.0   0.000005       0.999967   \n",
       "208693             is           1      1  209165.0   0.000005       0.999971   \n",
       "208856          proud           1      1  209166.0   0.000005       0.999976   \n",
       "208599             to           1      1  209167.0   0.000005       0.999981   \n",
       "209137             be           1      1  209168.0   0.000005       0.999986   \n",
       "208879              a           1      1  209169.0   0.000005       0.999990   \n",
       "209044      drug-free           1      1  209170.0   0.000005       0.999995   \n",
       "208786    workplace.'           1      1  209171.0   0.000005       1.000000   \n",
       "\n",
       "        appears_in_pct  \n",
       "19            0.002347  \n",
       "101           0.002347  \n",
       "92            0.002347  \n",
       "56            0.002347  \n",
       "47            0.002347  \n",
       "10            0.002347  \n",
       "1             0.002347  \n",
       "83            0.002347  \n",
       "74            0.002347  \n",
       "38            0.002347  \n",
       "28            0.002347  \n",
       "110           0.002347  \n",
       "99            0.002347  \n",
       "64            0.002347  \n",
       "54            0.002347  \n",
       "17            0.002347  \n",
       "8             0.002347  \n",
       "90            0.002347  \n",
       "81            0.002347  \n",
       "45            0.002347  \n",
       "36            0.002347  \n",
       "117           0.002347  \n",
       "108           0.002347  \n",
       "72            0.002347  \n",
       "62            0.002347  \n",
       "26            0.002347  \n",
       "15            0.002347  \n",
       "97            0.002347  \n",
       "88            0.002347  \n",
       "52            0.002347  \n",
       "...                ...  \n",
       "208622        0.002347  \n",
       "208973        0.002347  \n",
       "208902        0.002347  \n",
       "208645        0.002347  \n",
       "208809        0.002347  \n",
       "209160        0.002347  \n",
       "209089        0.002347  \n",
       "208831        0.002347  \n",
       "208995        0.002347  \n",
       "208738        0.002347  \n",
       "208667        0.002347  \n",
       "209017        0.002347  \n",
       "208574        0.002347  \n",
       "208924        0.002347  \n",
       "208578        0.002347  \n",
       "208928        0.002347  \n",
       "209093        0.002347  \n",
       "208835        0.002347  \n",
       "208763        0.002347  \n",
       "209114        0.002347  \n",
       "208671        0.002347  \n",
       "209021        0.002347  \n",
       "208950        0.002347  \n",
       "208693        0.002347  \n",
       "208856        0.002347  \n",
       "208599        0.002347  \n",
       "209137        0.002347  \n",
       "208879        0.002347  \n",
       "209044        0.002347  \n",
       "208786        0.002347  \n",
       "\n",
       "[209171 rows x 7 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'other' has incorrect type (expected spacy.tokens.token.Token, got str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-dca0dde0f657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwc_top20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msquarify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwc_top20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pct_total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwc_top20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/squarify/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(sizes, norm_x, norm_y, color, label, value, ax, pad, bar_kwargs, text_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"center\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtext_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self, x, y, s, fontdict, withdash, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             t = mtext.Text(\n\u001b[0;32m--> 722\u001b[0;31m                 x=x, y=y, text=s)\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, text, color, verticalalignment, horizontalalignment, multialignment, fontproperties, rotation, linespacing, rotation_mode, usetex, wrap, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_usetex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musetex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mset_text\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'other' has incorrect type (expected spacy.tokens.token.Token, got str)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wc_top20 = wc[wc['rank']<=20]\n",
    "\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'],alpha=.8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "sparse = tfidf.fit_transform(df.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tfidf = pd.DataFrame(sparse.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  02115   03  0356   04  062  06366   08   10  ...  zenreach  zero  \\\n",
       "0  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "1  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "2  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "3  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "4  0.0  0.0    0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0  ...       0.0   0.0   \n",
       "\n",
       "   zeus   zf     zheng  zillow  zones  zoom  zuckerberg  zurich  \n",
       "0   0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "1   0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "2   0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "3   0.0  0.0  0.104421     0.0    0.0   0.0         0.0     0.0  \n",
       "4   0.0  0.0  0.000000     0.0    0.0   0.0         0.0     0.0  \n",
       "\n",
       "[5 rows x 9818 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dist_matrix = cosine_similarity(dtm_tfidf)\n",
    "dist = pd.DataFrame(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.000000\n",
       "276    0.153965\n",
       "336    0.148508\n",
       "274    0.126799\n",
       "338    0.117706\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[0].nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\\\nHands on experience in SQL/Hive or similar programming language\\\\nMust show past work via GitHub, Kaggle or any other published article\\\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\\\nApply Now\"'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Facebook\\'s mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we\\'re building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we\\'re creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities \\\\xe2\\\\x80\\\\x94 we\\'re just getting started.\\\\nThe Infrastructure Strategy group is responsible for the strategic analysis to support and enable the continued growth critical to Facebook\\\\xe2\\\\x80\\\\x99s infrastructure organization. The ideal candidate will be passionate about Facebook, have strong analytical and modeling aptitude and has experience using data to drive cost effective decision making.\\\\n\\\\nRESPONSIBILITIES\\\\nLeverage data and business principles to solve large-scale web, mobile and data infrastructure problems.\\\\nWork cross-functionally to define problem statements, collect data, build analytical models and make recommendations.\\\\nBuild and maintain data driven optimization models, experiments, forecasting algorithms, and machine learning models.\\\\nLeverage tools like Python, R, Hadoop &amp; SQL to drive efficient analytics.\\\\nCommunicate final recommendations and drive decision making.\\\\nMINIMUM QUALIFICATIONS\\\\nDegree in quantitative field (e.g. Computer Science, Engineering, Mathematics, Statistics, Operations Research or other related field)\\\\n2+ years of industry or graduate research experience solving analytical problems and building models using quantitative, statistical or machine learning approaches\\\\nExperience with Machine Learning, Statistics, or other data analysis tools and techniques\\\\nExperience performing data extraction, cleaning, analysis and presentation for medium to large datasets\\\\nExperience with at least one programming language (i.e. Python, R, Java, or C++)\\\\nExperience writing SQL queries\\\\nExperience with scientific computing and analysis packages such as NumPy, SciPy, Pandas, Scikit-learn, dplyr, or ggplot2\\\\nExperience with statistics methods such as forecasting, time series, hypothesis testing, classification, clustering or regression analysis\\\\nExperience with data visualization libraries such as Matplotlib, Pyplot, ggplot2\\\\nExperience with machine learning libraries and packages such as PyTorch, Caffe2, TensorFlow, Keras or Theano\\\\nPREFERRED QUALIFICATIONS\\\\nAdvanced degree (Master\\\\xe2\\\\x80\\\\x99s or PhD) in quantitative field\\\\nExperience working with distributed computing tools (Hadoop, Hive, Spark, etc.)\\\\nProficiency in algorithmic complexity\"'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[276]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "nn.fit(dtm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.30079588, 1.30498405, 1.32151492, 1.32837826]]),\n",
       " array([[  0, 276, 336, 274, 338]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm_tfidf.iloc[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.32952097, 1.33426338, 1.33549162, 1.33549162, 1.34187539]]),\n",
       " array([[185, 331, 184, 147, 172]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_description = ['Seeking data scientist for fast paced exciting cutting edge in gaming industry.']\n",
    "\n",
    "query = tfidf.transform(ideal_description)\n",
    "\n",
    "nn.kneighbors(query.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'Full-time Position\\\\n\\\\nThe Senior Data Scientist will be a skilled problem solver who has a passion for utilizing data to drive business decisions and interest in driving the sports industry forward. The position will involve working closely with the analytics and business intelligence teams for the planning, execution, and delivery of all KAGR analytics and data science products. Products may include a variety of predictive models, marketing analytics, forecasting, development of sales and business analytics, etc. Additionally, the Senior Data Scientist will be responsible for building new expertise within the Analytics &amp; Data Science team through training and product R&amp;D.\\\\nThe Company\\\\nKraft Analytics Group (KAGR) is technology and services company comprised of a brilliant group of data science and data analytics professionals who are at the top of their game in the sports and entertainment industry. This company is all about data-driven decision making that focuses on growing the bottom line. They leverage their proprietary technology platform to power clients across the major U.S. sports leagues, college athletics. This environment is innovative, technically stimulating, fast-paced and exciting. From the inspirational leadership of CEO Jessica Gelman, the basketball court conference room to the and the office view that overlooks Gillette Stadium, everything about this culture is high-energy.\\\\nDuties &amp; Responsibilities\\\\nBuild tools to scrape, compile, standardize, and analyze data sets\\\\nResearch, design and prototype scalable models based on machine learning, data mining, and statistical modeling\\\\nSynthesis and present meaningful insights and recommendations to internal and external stakeholders\\\\nMaintain and document all work associated to analyses and data science products\\\\nDevelop standard approach to model automation &amp; integrate models into KAGR visualizations\\\\nContribute to marketing analytics and advanced market research efforts\\\\nCollaborate with cross-functional groups and create custom solutions as needed\\\\nEvaluate new technology opportunities and gaps\\\\nMaintain domain expertise relevant to industry standards and best practices\\\\nTrain Analytics &amp; Data Science team members on cutting edge techniques and technologies\\\\nSupervisory Responsibilities\\\\nThis position has no supervisory responsibilities.\\\\nSkills &amp; Qualifications\\\\nMaster\\\\xe2\\\\x80\\\\x99s Degree in Statistics, Economics, Mathematics, Computer Science, Data Science, or quantitative discipline\\\\n4+ years\\\\xe2\\\\x80\\\\x99 experience utilizing data science techniques (Supervised, Unsupervised, Time Series, Forecasting, Modeling, etc.) to solve business problems with large data sets\\\\nExpertise in Excel, SQL, and R and/or Python required\\\\nExperience developing and putting Machine Learning Algorithms into production\\\\nUnderstanding and willingness to continue learning advanced statistical analysis and modeling\\\\nAbility to present complex data sets and analysis in easy to understand ways\\\\nExcellent analytical and problem-solving skills\\\\nAbility to work within a diverse team and serve a variety of stakeholders with different priorities\\\\nOutstanding organizational skills and attention to detail\\\\nAbility and willingness to train and coach junior team members on data science techniques\\\\nStrong project management skills and knowledge of Data Analytics Lifecycle\\\\nExperience with Reinforcement Learning, Association Rules, Natural Language Processing preferred\\\\nExperience with AWS, or other major Machine Learning tools designed for handling Big Data preferred\\\\nExperience with data extraction via Web Scraping preferred\\\\nPhysical Demands\\\\nSitting for extended periods of time\\\\nDexterity of hands and fingers to operate a computer keyboard, mouse, and other computing equipment\\\\nThe employee frequently is required to talk or hear\\\\nThe employee is occasionally required to reach with hands and arms\\\\nSpecific vision abilities required by this job include close vision, distance vision, color vision, peripheral vision, depth perception, and ability to adjust focus\\\\nReasonable accommodations may be made to enable individuals with disabilities to perform the essential functions\\\\nWork Environment\\\\nThe noise level in the work environment is usually moderate\\\\nFast paced office environment\\\\nCertificates, Licenses, Registrations\\\\nNone required\\\\nOther Duties\\\\nPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.\\\\n\\\\nThis company is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics.'\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[185]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
